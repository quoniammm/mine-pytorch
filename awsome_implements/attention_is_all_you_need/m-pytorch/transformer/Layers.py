import torch.nn as nn
from transformer.SubLayers import MultiHeadAttention, PositionwiseFeedForward

def EncoderLayer(nn.Moudle):
    def __init__(self, ):
        pass

    def forward(self, ):
        pass

def DecoderLayer(nn.Module):
    def __init__(self, ):
        pass

    def forward(self, ):
        pass

