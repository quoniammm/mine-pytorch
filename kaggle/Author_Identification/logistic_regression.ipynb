{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotly\n",
    "plotly.tools.set_credentials_file(username='quoniammm', api_key='IF7kV6idFRdoo7LdgGRp')\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import nltk\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "sample = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47557\n",
      "test length: 8392\n",
      "train length: 17621\n",
      "valid length: 1958\n",
      "861\n"
     ]
    }
   ],
   "source": [
    "# bag_words\n",
    "all_words = set(train['text'].str.split(expand=True).unstack())\n",
    "\n",
    "def wordandindex(vocab):\n",
    "    return {word: i + 3 for i, word in enumerate(vocab)}, {i + 3: word for i, word in enumerate(vocab)}\n",
    "\n",
    "word2index, index2word = wordandindex(all_words)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "# 数据集准备\n",
    "X = np.array(train.text.apply(lambda sen: [word2index[word] for word in sen.split(' ')]))\n",
    "y = np.array(label_encoder.fit_transform(train.author))\n",
    "assert len(X) == len(y)\n",
    "print(len(all_words))\n",
    "#print(len(train))\n",
    "print(\"test length: {}\".format(len(test)))\n",
    "# 句子填充\n",
    "X_pad = np.zeros((19579, 861))\n",
    "\n",
    "for i in range(X_pad.shape[0]):\n",
    "    for j in range(len(X[i])):\n",
    "        X_pad[i, j] = X[i][j]\n",
    "\n",
    "xtrain, xvalid, ytrain, yvalid = train_test_split(\n",
    "    X_pad, y, \n",
    "    stratify=y, \n",
    "    random_state=42, \n",
    "    test_size=0.1, \n",
    "    shuffle=True\n",
    ")\n",
    "print(\"train length: {}\".format(len(xtrain)))\n",
    "#print(xtrain.type)\n",
    "print(\"valid length: {}\".format(len(xvalid)))\n",
    "#print(xvalid.type)\n",
    "\n",
    "# 最长句子长度设置为 input_size\n",
    "max = 0\n",
    "for i, x in enumerate(X):\n",
    "    # print(len(x))\n",
    "    if len(x) > max:\n",
    "        max = len(x)\n",
    "        \n",
    "print(max)\n",
    "# train.iloc[9215].values\n",
    "\n",
    "# 参数\n",
    "input_size = 861\n",
    "num_classes = 3\n",
    "epochs = 30\n",
    "lr = 1e-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 逻辑回归\n",
    "class LR(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(LR, self).__init__()\n",
    "        self.linear_0 = nn.Linear(input_size, 8192)\n",
    "        self.linear_1 = nn.Linear(8192, 4096)\n",
    "        self.linear_2 = nn.Linear(4096, 2048)\n",
    "        self.linear_3 = nn.Linear(2048, 512)\n",
    "        self.linear_4 = nn.Linear(512, 128)\n",
    "        self.linear_5 = nn.Linear(128, 64)\n",
    "        self.linear_6 = nn.Linear(64, 32)\n",
    "        self.linear_7 = nn.Linear(32, num_classes)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        L1_out = F.elu(self.linear_0(x))\n",
    "        L2_out = F.elu(self.linear_1(L1_out))\n",
    "        L3_out = F.elu(self.linear_2(L2_out))\n",
    "        L4_out = F.elu(self.linear_3(L3_out))\n",
    "        L5_out = F.elu(self.linear_4(L4_out))\n",
    "        L6_out = F.elu(self.linear_5(L5_out))\n",
    "        L7_out = F.elu(self.linear_6(L6_out))\n",
    "        \n",
    "        \n",
    "        final_out = F.log_softmax(self.linear_7(L7_out), dim=1)\n",
    "        logits = F.softmax(self.linear_7(L7_out), dim=1)\n",
    "        \n",
    "        return final_out, logits\n",
    "    \n",
    "model = LR(input_size, num_classes)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LR(\n",
       "  (linear_0): Linear(in_features=861, out_features=8192)\n",
       "  (linear_1): Linear(in_features=8192, out_features=4096)\n",
       "  (linear_2): Linear(in_features=4096, out_features=2048)\n",
       "  (linear_3): Linear(in_features=2048, out_features=512)\n",
       "  (linear_4): Linear(in_features=512, out_features=128)\n",
       "  (linear_5): Linear(in_features=128, out_features=64)\n",
       "  (linear_6): Linear(in_features=64, out_features=32)\n",
       "  (linear_7): Linear(in_features=32, out_features=3)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.354103088378906\n",
      "2.432854652404785\n",
      "1.5135761499404907\n",
      "1.1455076932907104\n",
      "1.113584041595459\n",
      "1.1097564697265625\n",
      "1.095628023147583\n",
      "1.1014715433120728\n",
      "1.0897088050842285\n",
      "1.1368136405944824\n",
      "1.1015968322753906\n",
      "1.1070098876953125\n",
      "1.1029592752456665\n",
      "1.1216243505477905\n",
      "1.0948398113250732\n",
      "1.165429711341858\n",
      "1.1039444208145142\n",
      "1.1403807401657104\n",
      "1.178102970123291\n",
      "1.1580079793930054\n",
      "1.099636435508728\n",
      "1.257710337638855\n",
      "1.2039588689804077\n",
      "1.1918848752975464\n",
      "1.138580083847046\n",
      "1.1326384544372559\n",
      "1.1586968898773193\n",
      "1.1722626686096191\n",
      "1.23837411403656\n",
      "1.184097409248352\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "train_acc = []\n",
    "valid_acc = []\n",
    "for epoch in range(epochs):\n",
    "    vx = Variable(torch.FloatTensor(xtrain)).cuda()\n",
    "    vy = Variable(torch.LongTensor(ytrain)).cuda()\n",
    "    vx_valid = Variable(torch.FloatTensor(xvalid)).cuda()\n",
    "    vy_valid = Variable(torch.LongTensor(yvalid)).cuda()\n",
    "    losss = []\n",
    "    optimizer.zero_grad()\n",
    "    for i in range(0, len(xtrain), 256):\n",
    "        if i + 256 > len(xtrain):\n",
    "            vx_batch = vx[i:len(xtrain)]\n",
    "            vy_batch = vy[i:len(xtrain)]\n",
    "        else:\n",
    "            vx_batch = vx[i:i+256]\n",
    "            vy_batch = vy[i:i+256]\n",
    "            \n",
    "        \n",
    "        outputs, results = model(vx_batch)\n",
    "        \n",
    "        if not i % 25600:\n",
    "            _, ressults_valid = model(vx_valid)\n",
    "            _, res = results.data.max(1)\n",
    "            _, res_valid = ressults_valid.data.max(1)\n",
    "            ta = (torch.sum(res == vy_batch.data) + 0.0) / 256.0\n",
    "            va = (torch.sum(res_valid == vy_valid.data) + 0.0) / len(yvalid)\n",
    "            train_acc.append(ta)\n",
    "            valid_acc.append(va)\n",
    "        \n",
    "        loss = criterion(outputs, vy_batch)\n",
    "        loss.backward()\n",
    "        losss.append(loss)\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(loss.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~quoniammm/2.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = len(train_acc)\n",
    "print(N)\n",
    "random_x = np.linspace(0, 1, N)\n",
    "random_y0 = np.array(train_acc)\n",
    "random_y1 = np.array(valid_acc)\n",
    "\n",
    "# Create traces\n",
    "trace0 = go.Scatter(\n",
    "    x = random_x,\n",
    "    y = random_y0,\n",
    "    mode = 'lines',\n",
    "    name = 'train_acc'\n",
    ")\n",
    "trace1 = go.Scatter(\n",
    "    x = random_x,\n",
    "    y = random_y1,\n",
    "    mode = 'lines',\n",
    "    name = 'valid_acc'\n",
    ")\n",
    "\n",
    "data = [trace0, trace1]\n",
    "\n",
    "py.iplot(data, filename='line-mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.6519  0.2730  0.0751\n",
       " 0.4462  0.2754  0.2785\n",
       " 0.2418  0.4984  0.2598\n",
       "           ⋮            \n",
       " 0.2638  0.4933  0.2429\n",
       " 0.5463  0.1870  0.2667\n",
       " 0.4335  0.1428  0.4237\n",
       "[torch.FloatTensor of size 8392x3]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_deal(x):\n",
    "    sen_vec = []\n",
    "    for word in x.split(' '):\n",
    "        if word not in all_words:\n",
    "            sen_vec.append(2)\n",
    "        else:\n",
    "            sen_vec.append(word2index[word])\n",
    "            \n",
    "    return sen_vec\n",
    "            \n",
    "X_t = np.array(test.text.apply(test_deal))\n",
    "\n",
    "X_t_pad = np.zeros((8392, 861))\n",
    "\n",
    "for i in range(X_t_pad.shape[0]):\n",
    "    for j in range(len(X_t[i])):\n",
    "        X_t_pad[i, j] = X_t[i][j]\n",
    "        \n",
    "tt = Variable(torch.FloatTensor(X_t_pad))\n",
    "model.cpu()\n",
    "_, res = model(tt)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rr = pd.DataFrame(np.array(res.data), columns=['EAP', 'HPL', 'MWS'], index=test.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EAP</th>\n",
       "      <th>HPL</th>\n",
       "      <th>MWS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id02310</th>\n",
       "      <td>0.651887</td>\n",
       "      <td>0.273037</td>\n",
       "      <td>0.075077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id24541</th>\n",
       "      <td>0.446181</td>\n",
       "      <td>0.275357</td>\n",
       "      <td>0.278462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id00134</th>\n",
       "      <td>0.241819</td>\n",
       "      <td>0.498354</td>\n",
       "      <td>0.259826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id27757</th>\n",
       "      <td>0.284279</td>\n",
       "      <td>0.444009</td>\n",
       "      <td>0.271712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id04081</th>\n",
       "      <td>0.665469</td>\n",
       "      <td>0.213206</td>\n",
       "      <td>0.121325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              EAP       HPL       MWS\n",
       "id                                   \n",
       "id02310  0.651887  0.273037  0.075077\n",
       "id24541  0.446181  0.275357  0.278462\n",
       "id00134  0.241819  0.498354  0.259826\n",
       "id27757  0.284279  0.444009  0.271712\n",
       "id04081  0.665469  0.213206  0.121325"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>EAP</th>\n",
       "      <th>HPL</th>\n",
       "      <th>MWS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id02310</td>\n",
       "      <td>0.403494</td>\n",
       "      <td>0.287808</td>\n",
       "      <td>0.308698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id24541</td>\n",
       "      <td>0.403494</td>\n",
       "      <td>0.287808</td>\n",
       "      <td>0.308698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id00134</td>\n",
       "      <td>0.403494</td>\n",
       "      <td>0.287808</td>\n",
       "      <td>0.308698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27757</td>\n",
       "      <td>0.403494</td>\n",
       "      <td>0.287808</td>\n",
       "      <td>0.308698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id04081</td>\n",
       "      <td>0.403494</td>\n",
       "      <td>0.287808</td>\n",
       "      <td>0.308698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id       EAP       HPL       MWS\n",
       "0  id02310  0.403494  0.287808  0.308698\n",
       "1  id24541  0.403494  0.287808  0.308698\n",
       "2  id00134  0.403494  0.287808  0.308698\n",
       "3  id27757  0.403494  0.287808  0.308698\n",
       "4  id04081  0.403494  0.287808  0.308698"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rr.to_csv('222.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
