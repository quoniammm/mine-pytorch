{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3260\n",
      "3091\n",
      "Pipeline...\n",
      "(3321, 50)\n",
      "(5668, 50)\n",
      "[0]\ttrain-mlogloss:2.14625\tvalid-mlogloss:2.1518\n",
      "Multiple eval metrics have been passed: 'valid-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-mlogloss hasn't improved in 50 rounds.\n",
      "[50]\ttrain-mlogloss:1.22697\tvalid-mlogloss:1.37848\n",
      "[100]\ttrain-mlogloss:0.962159\tvalid-mlogloss:1.20367\n",
      "[150]\ttrain-mlogloss:0.811314\tvalid-mlogloss:1.13104\n",
      "[200]\ttrain-mlogloss:0.707752\tvalid-mlogloss:1.0993\n",
      "[250]\ttrain-mlogloss:0.628141\tvalid-mlogloss:1.07859\n",
      "[300]\ttrain-mlogloss:0.564709\tvalid-mlogloss:1.06977\n",
      "[350]\ttrain-mlogloss:0.511379\tvalid-mlogloss:1.06579\n",
      "[400]\ttrain-mlogloss:0.466618\tvalid-mlogloss:1.06384\n",
      "[450]\ttrain-mlogloss:0.42542\tvalid-mlogloss:1.06362\n",
      "Stopping. Best iteration:\n",
      "[425]\ttrain-mlogloss:0.446482\tvalid-mlogloss:1.06274\n",
      "\n",
      "1.06274187544\n"
     ]
    }
   ],
   "source": [
    "from sklearn import *\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "train = pd.read_csv('training_variants')\n",
    "test = pd.read_csv('test_variants')\n",
    "trainx = pd.read_csv('training_text', sep=\"\\|\\|\", engine='python', header=None, skiprows=1, names=[\"ID\",\"Text\"])\n",
    "testx = pd.read_csv('test_text', sep=\"\\|\\|\", engine='python', header=None, skiprows=1, names=[\"ID\",\"Text\"])\n",
    "\n",
    "train = pd.merge(train, trainx, how='left', on='ID').fillna('')\n",
    "y = train['Class'].values\n",
    "train = train.drop(['Class'], axis=1)\n",
    "\n",
    "test = pd.merge(test, testx, how='left', on='ID').fillna('')\n",
    "pid = test['ID'].values\n",
    "\n",
    "df_all = pd.concat((train, test), axis=0, ignore_index=True)\n",
    "df_all['Gene_Share'] = df_all.apply(lambda r: sum([1 for w in r['Gene'].split(' ') if w in r['Text'].split(' ')]), axis=1)\n",
    "df_all['Variation_Share'] = df_all.apply(lambda r: sum([1 for w in r['Variation'].split(' ') if w in r['Text'].split(' ')]), axis=1)\n",
    "\n",
    "#commented for Kaggle Limits\n",
    "#for i in range(56):\n",
    "#    df_all['Gene_'+str(i)] = df_all['Gene'].map(lambda x: str(x[i]) if len(x)>i else '')\n",
    "#    df_all['Variation'+str(i)] = df_all['Variation'].map(lambda x: str(x[i]) if len(x)>i else '')\n",
    "\n",
    "\n",
    "gen_var_lst = sorted(list(train.Gene.unique()) + list(train.Variation.unique()))\n",
    "print(len(gen_var_lst))\n",
    "gen_var_lst = [x for x in gen_var_lst if len(x.split(' '))==1]\n",
    "print(len(gen_var_lst))\n",
    "i_ = 0\n",
    "#commented for Kaggle Limits\n",
    "#for gen_var_lst_itm in gen_var_lst:\n",
    "#    if i_ % 100 == 0: print(i_)\n",
    "#    df_all['GV_'+str(gen_var_lst_itm)] = df_all['Text'].map(lambda x: str(x).count(str(gen_var_lst_itm)))\n",
    "#    i_ += 1\n",
    "\n",
    "for c in df_all.columns:\n",
    "    if df_all[c].dtype == 'object':\n",
    "        if c in ['Gene','Variation']:\n",
    "            lbl = preprocessing.LabelEncoder()\n",
    "            df_all[c+'_lbl_enc'] = lbl.fit_transform(df_all[c].values)  \n",
    "            df_all[c+'_len'] = df_all[c].map(lambda x: len(str(x)))\n",
    "            df_all[c+'_words'] = df_all[c].map(lambda x: len(str(x).split(' ')))\n",
    "        elif c != 'Text':\n",
    "            lbl = preprocessing.LabelEncoder()\n",
    "            df_all[c] = lbl.fit_transform(df_all[c].values)\n",
    "        if c=='Text': \n",
    "            df_all[c+'_len'] = df_all[c].map(lambda x: len(str(x)))\n",
    "            df_all[c+'_words'] = df_all[c].map(lambda x: len(str(x).split(' '))) \n",
    "\n",
    "train = df_all.iloc[:len(train)]\n",
    "test = df_all.iloc[len(train):]\n",
    "\n",
    "class cust_regression_vals(sklearn.base.BaseEstimator, sklearn.base.TransformerMixin):\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    def transform(self, x):\n",
    "        x = x.drop(['Gene', 'Variation','ID','Text'],axis=1).values\n",
    "        return x\n",
    "\n",
    "class cust_txt_col(sklearn.base.BaseEstimator, sklearn.base.TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    def transform(self, x):\n",
    "        return x[self.key].apply(str)\n",
    "\n",
    "print('Pipeline...')\n",
    "fp = pipeline.Pipeline([\n",
    "    ('union', pipeline.FeatureUnion(\n",
    "        n_jobs = -1,\n",
    "        transformer_list = [\n",
    "            ('standard', cust_regression_vals()),\n",
    "            ('pi1', pipeline.Pipeline([('Gene', cust_txt_col('Gene')), ('count_Gene', feature_extraction.text.CountVectorizer(analyzer=u'char', ngram_range=(1, 8))), ('tsvd1', decomposition.TruncatedSVD(n_components=20, n_iter=25, random_state=12))])),\n",
    "            ('pi2', pipeline.Pipeline([('Variation', cust_txt_col('Variation')), ('count_Variation', feature_extraction.text.CountVectorizer(analyzer=u'char', ngram_range=(1, 8))), ('tsvd2', decomposition.TruncatedSVD(n_components=20, n_iter=25, random_state=12))])),\n",
    "            #commented for Kaggle Limits\n",
    "            #('pi3', pipeline.Pipeline([('Text', cust_txt_col('Text')), ('tfidf_Text', feature_extraction.text.TfidfVectorizer(ngram_range=(1, 2))), ('tsvd3', decomposition.TruncatedSVD(n_components=50, n_iter=25, random_state=12))]))\n",
    "        ])\n",
    "    )])\n",
    "\n",
    "train = fp.fit_transform(train); print(train.shape)\n",
    "test = fp.transform(test); print(test.shape)\n",
    "\n",
    "y = y - 1 #fix for zero bound array\n",
    "\n",
    "denom = 0\n",
    "fold = 1 #Change to 5, 1 for Kaggle Limits\n",
    "for i in range(fold):\n",
    "    params = {\n",
    "        'eta': 0.03333,\n",
    "        'max_depth': 4,\n",
    "        'objective': 'multi:softprob',\n",
    "        'eval_metric': 'mlogloss',\n",
    "        'num_class': 9,\n",
    "        'seed': i,\n",
    "        'silent': True\n",
    "    }\n",
    "    x1, x2, y1, y2 = model_selection.train_test_split(train, y, test_size=0.18, random_state=i)\n",
    "    watchlist = [(xgb.DMatrix(x1, y1), 'train'), (xgb.DMatrix(x2, y2), 'valid')]\n",
    "    model = xgb.train(params, xgb.DMatrix(x1, y1), 5000,  watchlist, verbose_eval=50, early_stopping_rounds=50)\n",
    "    score1 = metrics.log_loss(y2, model.predict(xgb.DMatrix(x2), ntree_limit=model.best_ntree_limit), labels = list(range(9)))\n",
    "    print(score1)\n",
    "    #if score < 0.9:\n",
    "    if denom != 0:\n",
    "        pred = model.predict(xgb.DMatrix(test), ntree_limit=model.best_ntree_limit+80)\n",
    "        preds += pred\n",
    "    else:\n",
    "        pred = model.predict(xgb.DMatrix(test), ntree_limit=model.best_ntree_limit+80)\n",
    "        preds = pred.copy()\n",
    "    denom += 1\n",
    "    submission = pd.DataFrame(pred, columns=['class'+str(c+1) for c in range(9)])\n",
    "    submission['ID'] = pid\n",
    "    submission.to_csv('submission_xgb_fold_'  + str(i) + '.csv', index=False)\n",
    "preds /= denom\n",
    "submission = pd.DataFrame(preds, columns=['class'+str(c+1) for c in range(9)])\n",
    "submission['ID'] = pid\n",
    "submission.to_csv('submission_xgb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
