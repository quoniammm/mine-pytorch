{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quoniammm/anaconda3/envs/py3Tfgpu/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quoniammm/anaconda3/envs/py3Tfgpu/lib/python3.6/site-packages/ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "/home/quoniammm/anaconda3/envs/py3Tfgpu/lib/python3.6/site-packages/ipykernel_launcher.py:4: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "path = 'data_rct/'\n",
    "df_train_txt = pd.read_csv(path + 'training_text', sep='\\|\\|', header=None, skiprows=1, names=[\"ID\",\"Text\"])\n",
    "df_train_var = pd.read_csv(path + 'training_variants')\n",
    "df_test_txt = pd.read_csv(path + 'stage2_test_text.csv', sep='\\|\\|', header=None, skiprows=1, names=[\"ID\",\"Text\"])\n",
    "df_test_var = pd.read_csv(path + 'stage2_test_variants.csv')\n",
    "df_train = pd.merge(df_train_var, df_train_txt, how='left', on='ID')\n",
    "df_test = pd.merge(df_test_var, df_test_txt, how='left', on='ID')\n",
    "col = ['ID', 'Gene', 'Variation', 'Text', 'Class']\n",
    "df_train = df_train.loc[:, col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gene</th>\n",
       "      <th>Variation</th>\n",
       "      <th>Text</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>FAM58A</td>\n",
       "      <td>Truncating Mutations</td>\n",
       "      <td>Cyclin-dependent kinases (CDKs) regulate a var...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CBL</td>\n",
       "      <td>W802*</td>\n",
       "      <td>Abstract Background  Non-small cell lung canc...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CBL</td>\n",
       "      <td>Q249E</td>\n",
       "      <td>Abstract Background  Non-small cell lung canc...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>CBL</td>\n",
       "      <td>N454D</td>\n",
       "      <td>Recent evidence has demonstrated that acquired...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>CBL</td>\n",
       "      <td>L399V</td>\n",
       "      <td>Oncogenic mutations in the monomeric Casitas B...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID    Gene             Variation  \\\n",
       "0   0  FAM58A  Truncating Mutations   \n",
       "1   1     CBL                 W802*   \n",
       "2   2     CBL                 Q249E   \n",
       "3   3     CBL                 N454D   \n",
       "4   4     CBL                 L399V   \n",
       "\n",
       "                                                Text  Class  \n",
       "0  Cyclin-dependent kinases (CDKs) regulate a var...      1  \n",
       "1   Abstract Background  Non-small cell lung canc...      2  \n",
       "2   Abstract Background  Non-small cell lung canc...      2  \n",
       "3  Recent evidence has demonstrated that acquired...      3  \n",
       "4  Oncogenic mutations in the monomeric Casitas B...      4  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3321"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gene</th>\n",
       "      <th>Variation</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>CHEK2</td>\n",
       "      <td>H371Y</td>\n",
       "      <td>The incidence of breast cancer is increasing i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>AXIN2</td>\n",
       "      <td>Truncating Mutations</td>\n",
       "      <td>An unselected series of 310 colorectal carcino...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>WNT4</td>\n",
       "      <td>E216G</td>\n",
       "      <td>Mycosis fungoides and Sézary syndrome are prim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>SUCLA2</td>\n",
       "      <td>G118R</td>\n",
       "      <td>Regulated progression through the cell cycle ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>BRAF</td>\n",
       "      <td>T599insTT</td>\n",
       "      <td>Pilocytic astrocytoma (PA) is emerging as a tu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID    Gene             Variation  \\\n",
       "0   1   CHEK2                 H371Y   \n",
       "1   2   AXIN2  Truncating Mutations   \n",
       "2   3    WNT4                 E216G   \n",
       "3   4  SUCLA2                 G118R   \n",
       "4   5    BRAF             T599insTT   \n",
       "\n",
       "                                                Text  \n",
       "0  The incidence of breast cancer is increasing i...  \n",
       "1  An unselected series of 310 colorectal carcino...  \n",
       "2  Mycosis fungoides and Sézary syndrome are prim...  \n",
       "3   Regulated progression through the cell cycle ...  \n",
       "4  Pilocytic astrocytoma (PA) is emerging as a tu...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3321"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_train[['Text']]\n",
    "X_test = df_test[['Text']]\n",
    "X_array = np.concatenate((X.values), axis=0)\n",
    "len(X_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_counts = Counter()\n",
    "counts1 = Counter()\n",
    "counts2 = Counter()\n",
    "counts3 = Counter()\n",
    "counts4 = Counter()\n",
    "counts5 = Counter()\n",
    "counts6 = Counter()\n",
    "counts7 = Counter()\n",
    "counts8 = Counter()\n",
    "counts9 = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "438158"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(X_array)):\n",
    "    if df_train['Class'][i] == 1:\n",
    "        for sent in list(str(X_array[i]).split('.')):\n",
    "            for word in sent.split(' '):\n",
    "                total_counts[word] += 1\n",
    "                counts1[word] += 1\n",
    "    elif df_train['Class'][i] == 2:\n",
    "        for sent in list(str(X_array[i]).split('.')):\n",
    "            for word in sent.split(' '):\n",
    "                total_counts[word] += 1\n",
    "                counts2[word] += 1\n",
    "    elif df_train['Class'][i] == 3:\n",
    "        for sent in list(str(X_array[i]).split('.')):\n",
    "            for word in sent.split(' '):\n",
    "                total_counts[word] += 1\n",
    "                counts3[word] += 1\n",
    "    elif df_train['Class'][i] == 4:\n",
    "        for sent in list(str(X_array[i]).split('.')):\n",
    "            for word in sent.split(' '):\n",
    "                total_counts[word] += 1\n",
    "                counts4[word] += 1\n",
    "    elif df_train['Class'][i] == 5:\n",
    "        for sent in list(str(X_array[i]).split('.')):\n",
    "            for word in sent.split(' '):\n",
    "                total_counts[word] += 1\n",
    "                counts5[word] += 1\n",
    "    elif df_train['Class'][i] == 6:\n",
    "        for sent in list(str(X_array[i]).split('.')):\n",
    "            for word in sent.split(' '):\n",
    "                total_counts[word] += 1\n",
    "                counts6[word] += 1\n",
    "    elif df_train['Class'][i] == 7:\n",
    "        for sent in list(str(X_array[i]).split('.')):\n",
    "            for word in sent.split(' '):\n",
    "                total_counts[word] += 1\n",
    "                counts7[word] += 1\n",
    "    elif df_train['Class'][i] == 8:\n",
    "        for sent in list(str(X_array[i]).split('.')):\n",
    "            for word in sent.split(' '):\n",
    "                total_counts[word] += 1\n",
    "                counts8[word] += 1\n",
    "    elif df_train['Class'][i] == 9:\n",
    "        for sent in list(str(X_array[i]).split('.')):\n",
    "            for word in sent.split(' '):\n",
    "                total_counts[word] += 1\n",
    "                counts9[word] += 1\n",
    "            \n",
    "\n",
    "vocab = set(total_counts.keys())\n",
    "vocab_size = len(vocab)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counts1_all_ratios = Counter()\n",
    "counts2_all_ratios = Counter()\n",
    "counts3_all_ratios = Counter()\n",
    "counts4_all_ratios = Counter()\n",
    "counts5_all_ratios = Counter()\n",
    "counts6_all_ratios = Counter()\n",
    "counts7_all_ratios = Counter()\n",
    "counts8_all_ratios = Counter()\n",
    "counts9_all_ratios = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for term,cnt in list(total_counts.most_common()):\n",
    "    if(cnt > 100):\n",
    "        ratio = counts1[term] / float(counts2[term] + counts3[term] + counts4[term] + counts5[term] + counts6[term] + counts7[term] + counts8[term] + counts9[term] + 1)\n",
    "        counts1_all_ratios[term] = ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for term,cnt in list(total_counts.most_common()):\n",
    "    if(cnt > 100):\n",
    "        ratio = counts2[term] / float(counts1[term] + counts3[term] + counts4[term] + counts5[term] + counts6[term] + counts7[term] + counts8[term] + counts9[term] + 1)\n",
    "        counts2_all_ratios[term] = ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for term,cnt in list(total_counts.most_common()):\n",
    "    if(cnt > 100):\n",
    "        ratio = counts3[term] / float(counts1[term] + counts2[term] + counts4[term] + counts5[term] + counts6[term] + counts7[term] + counts8[term] + counts9[term] + 1)\n",
    "        counts3_all_ratios[term] = ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for term,cnt in list(total_counts.most_common()):\n",
    "    if(cnt > 100):\n",
    "        ratio = counts4[term] / float(counts1[term] + counts2[term] + counts3[term] + counts5[term] + counts6[term] + counts7[term] + counts8[term] + counts9[term] + 1)\n",
    "        counts4_all_ratios[term] = ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for term,cnt in list(total_counts.most_common()):\n",
    "    if(cnt > 100):\n",
    "        ratio = counts5[term] / float(counts1[term] + counts2[term] + counts3[term] + counts4[term] + counts6[term] + counts7[term] + counts8[term] + counts9[term] + 1)\n",
    "        counts5_all_ratios[term] = ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for term,cnt in list(total_counts.most_common()):\n",
    "    if(cnt > 100):\n",
    "        ratio = counts6[term] / float(counts1[term] + counts2[term] + counts3[term] + counts4[term] + counts5[term] + counts7[term] + counts8[term] + counts9[term] + 1)\n",
    "        counts6_all_ratios[term] = ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for term,cnt in list(total_counts.most_common()):\n",
    "    if(cnt > 100):\n",
    "        ratio = counts7[term] / float(counts1[term] + counts2[term] + counts3[term] + counts4[term] + counts5[term] + counts6[term] + counts8[term] + counts9[term] + 1)\n",
    "        counts7_all_ratios[term] = ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for term,cnt in list(total_counts.most_common()):\n",
    "    if(cnt > 100):\n",
    "        ratio = counts8[term] / float(counts1[term] + counts2[term] + counts3[term] + counts4[term] + counts5[term] + counts6[term] + counts7[term] + counts9[term] + 1)\n",
    "        counts8_all_ratios[term] = ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for term,cnt in list(total_counts.most_common()):\n",
    "    if(cnt > 100):\n",
    "        ratio = counts9[term] / float(counts1[term] + counts2[term] + counts3[term] + counts4[term] + counts5[term] + counts6[term] + counts7[term] + counts8[term] + 1)\n",
    "        counts9_all_ratios[term] = ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# log value\n",
    "def convert_log(ratios):\n",
    "    for word,ratio in ratios.most_common():\n",
    "        if ratio == 0.0:\n",
    "            ratios[word] = 0.0\n",
    "        else:\n",
    "            ratios[word] = np.log(ratio)\n",
    "    return ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counts1_all_ratios_log = convert_log(counts1_all_ratios)\n",
    "counts2_all_ratios_log = convert_log(counts2_all_ratios)\n",
    "counts3_all_ratios_log = convert_log(counts3_all_ratios)\n",
    "counts4_all_ratios_log = convert_log(counts4_all_ratios)\n",
    "counts5_all_ratios_log = convert_log(counts5_all_ratios)\n",
    "counts6_all_ratios_log = convert_log(counts6_all_ratios)\n",
    "counts7_all_ratios_log = convert_log(counts7_all_ratios)\n",
    "counts8_all_ratios_log = convert_log(counts8_all_ratios)\n",
    "counts9_all_ratios_log = convert_log(counts9_all_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"9805a06a-e757-445b-845a-128f936c9eb8\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id !== undefined) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io import _state; print(_state.uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var element_id = msg.content.text.trim();\n",
       "            Bokeh.index[element_id].model.document.clear();\n",
       "            delete Bokeh.index[element_id];\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"from bokeh import io; io._destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(`.${CLASS_NAME.split(' ')[0]}`);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[0].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[0].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[0]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"9805a06a-e757-445b-845a-128f936c9eb8\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        root._bokeh_is_loading--;\n",
       "        if (root._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"9805a06a-e757-445b-845a-128f936c9eb8\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '9805a06a-e757-445b-845a-128f936c9eb8' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.9.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.9.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.9.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.9.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.9.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.9.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.9.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.9.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.9.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.9.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"9805a06a-e757-445b-845a-128f936c9eb8\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"9805a06a-e757-445b-845a-128f936c9eb8\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };var element = document.getElementById(\"9805a06a-e757-445b-845a-128f936c9eb8\");\n  if (element == null) {\n    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '9805a06a-e757-445b-845a-128f936c9eb8' but no matching script tag was found. \")\n    return false;\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.9.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.9.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.9.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.9.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.9.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.9.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.9.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.9.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.9.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.9.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"9805a06a-e757-445b-845a-128f936c9eb8\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bokeh.models import ColumnDataSource, LabelSet\n",
    "from bokeh.plotting import figure, show, output_file\n",
    "from bokeh.io import output_notebook\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div class=\"bk-root\">\n",
       "    <div class=\"bk-plotdiv\" id=\"299b99f7-9109-4da7-9834-b60522cbb5fe\"></div>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    var docs_json = {\"9c093681-8ea0-48d6-9792-daefe7667c18\":{\"roots\":{\"references\":[{\"attributes\":{},\"id\":\"5273f87a-cfac-4e66-8304-fb786ae4bf00\",\"type\":\"BasicTicker\"},{\"attributes\":{\"dimension\":1,\"plot\":{\"id\":\"4a061ec2-bb50-4051-b7ed-f044420699ea\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"5273f87a-cfac-4e66-8304-fb786ae4bf00\",\"type\":\"BasicTicker\"}},\"id\":\"178c5f39-1345-4bdf-8c92-0f1f1ddcdea6\",\"type\":\"Grid\"},{\"attributes\":{\"callback\":null,\"column_names\":[\"left\",\"right\",\"top\"],\"data\":{\"left\":{\"__ndarray__\":\"lEAQHvHoI8BBxmD+Q5gjwO5Lsd6WRyPAnNEBv+n2IsBJV1KfPKYiwPbcon+PVSLAo2LzX+IEIsBR6ENANbQhwP5tlCCIYyHAq/PkANsSIcBYeTXhLcIgwAb/hcGAcSDAs4TWodMgIMDAFE4ETaAfwBog78Ty/h7AdSuQhZhdHsDQNjFGPrwdwCpC0gbkGh3AhE1zx4l5HMDfWBSIL9gbwDpktUjVNhvAlG9WCXuVGsDuevfJIPQZwEmGmIrGUhnAo5E5S2yxGMD+nNoLEhAYwFioe8y3bhfAs7McjV3NFsANv71NAywWwGjKXg6pihXAwtX/zk7pFMAd4aCP9EcUwHfsQVCaphPA0ffiEEAFE8AsA4TR5WMSwIYOJZKLwhHA4RnGUjEhEcA7JWcT138QwCxhEKj5vA/A4HdSKUV6DsCWjpSqkDcNwEql1ivc9AvAALwYrSeyCsC00louc28JwGrpnK++LAjAHgDfMArqBsDUFiGyVacFwIgtYzOhZATAPESltOwhA8DyWuc1ON8BwKZxKbeDnADAuBDXcJ6z/r8gPltzNS78v4hr33XMqPm/+JhjeGMj979gxud6+p30v8jza32RGPK/YELg/1Am779AnegEfxvqvxD48AmtEOW/4FL5DtsF4L9gWwMoEvbVv0AiKGTcwMe/AGxMwqOsnL9AB5Vzs5XAPwDOua99YNI/YBippSF23D9QMczN4kXjP4DWw8i0UOg/sHu7w4Zb7T9wkFlfLDPxPwBj1VyVuPM/mDVRWv499j8wCM1XZ8P4P8jaSFXQSPs/WK3EUjnO/T/4PyAo0SkAQEQp3qaFbAFAkBKcJTqvAkDY+1mk7vEDQCTlFyOjNAVAcM7VoVd3BkC8t5MgDLoHQAihUZ/A/AhAUIoPHnU/CkCcc82cKYILQOhcixvexAxANEZJmpIHDkB8LwcZR0oPQGSM4st9RhBACoFBC9jnEECwdaBKMokRQFRq/4mMKhJA+l5eyebLEkCgU70IQW0TQEZIHEibDhRA7Dx7h/WvFECQMdrGT1EVQDYmOQaq8hVA3BqYRQSUFkA=\",\"dtype\":\"float64\",\"shape\":[100]},\"right\":{\"__ndarray__\":\"QcZg/kOYI8DuS7HelkcjwJzRAb/p9iLASVdSnzymIsD23KJ/j1UiwKNi81/iBCLAUehDQDW0IcD+bZQgiGMhwKvz5ADbEiHAWHk14S3CIMAG/4XBgHEgwLOE1qHTICDAwBROBE2gH8AaIO/E8v4ewHUrkIWYXR7A0DYxRj68HcAqQtIG5BodwIRNc8eJeRzA31gUiC/YG8A6ZLVI1TYbwJRvVgl7lRrA7nr3ySD0GcBJhpiKxlIZwKOROUtssRjA/pzaCxIQGMBYqHvMt24XwLOzHI1dzRbADb+9TQMsFsBoyl4OqYoVwMLV/85O6RTAHeGgj/RHFMB37EFQmqYTwNH34hBABRPALAOE0eVjEsCGDiWSi8IRwOEZxlIxIRHAOyVnE9d/EMAsYRCo+bwPwOB3UilFeg7Alo6UqpA3DcBKpdYr3PQLwAC8GK0nsgrAtNJaLnNvCcBq6ZyvviwIwB4A3zAK6gbA1BYhslWnBcCILWMzoWQEwDxEpbTsIQPA8lrnNTjfAcCmcSm3g5wAwLgQ13Ces/6/ID5bczUu/L+Ia991zKj5v/iYY3hjI/e/YMbnevqd9L/I82t9kRjyv2BC4P9QJu+/QJ3oBH8b6r8Q+PAJrRDlv+BS+Q7bBeC/YFsDKBL21b9AIihk3MDHvwBsTMKjrJy/QAeVc7OVwD8AzrmvfWDSP2AYqaUhdtw/UDHMzeJF4z+A1sPItFDoP7B7u8OGW+0/cJBZXywz8T8AY9VclbjzP5g1UVr+PfY/MAjNV2fD+D/I2khV0Ej7P1itxFI5zv0/+D8gKNEpAEBEKd6mhWwBQJASnCU6rwJA2PtZpO7xA0Ak5RcjozQFQHDO1aFXdwZAvLeTIAy6B0AIoVGfwPwIQFCKDx51PwpAnHPNnCmCC0DoXIsb3sQMQDRGSZqSBw5AfC8HGUdKD0BkjOLLfUYQQAqBQQvY5xBAsHWgSjKJEUBUav+JjCoSQPpeXsnmyxJAoFO9CEFtE0BGSBxImw4UQOw8e4f1rxRAkDHaxk9RFUA2JjkGqvIVQNwamEUElBZAgA/3hF41F0A=\",\"dtype\":\"float64\",\"shape\":[100]},\"top\":{\"__ndarray__\":\"ZLubGxWkOD8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGS7mxsVpDg/sbubGxWkOD8AAAAAAAAAAGS7mxsVpDg/isy01A97Uj+xu5sbFaRIP4rMtNQPe1I/PKqCYhrNXj88qoJiGs1eP4q7mxsVpFg/irubGxWkaD+KzLTUD3tyP0GIbiZRBXQ/irubGxWkeD9Dd1VtVi6KPz+ZeMQ1aYk/0DIPv5e4iz/YEOxnuH2cP8J/addeU6E/TvfceuFnpD8kNxn0G0unP387FA6Kaq4/73JaU+gOsz+xvSA2V222Px1owc6dIL4/MoUuDPmQwT8H5QjC0OXFPwzGJYVJH8k/lZy43o3dyz/1VDIWd/PKP5OsB31clsw/PpcCxQkT0D9LeBBtbNnOP1YLJzMeQMw/BNM0CcBjxz9+HEDsGBfGP/ZySzjSm74/uMEbUMWMvT/R/+HJ0xm3P4AM8U1KXrU/wb+WNYPDrz+t/+HJ0xmnP5tuUB5kfKc/xn9avEjgnD+/kHN1Q7eWP8BuUB5kfJc/PKqCYhrNjj/UEPuCzvCAP4CIbiZRBYQ/r+7XK++1gT/UEPuCzvBwP2S7mxsVpHg/JzMPv5e4az88qoJiGs1uP4rMtNQPe2I/isy01A97Yj+xu5sbFaRoPzyqgmIazV4/0Yv2QzTIBkA8qoJiGs1eP2S7mxsVpDg/sbubGxWkSD9ku5sbFaRYP2S7mxsVpEg/ZLubGxWkSD+eqoJiGs1eP2S7mxsVpDg/ZLubGxWkSD9ku5sbFaRIP7G7mxsVpFg/isy01A97Yj8AAAAAAAAAAAAAAAAAAAAAsbubGxWkOD9ku5sbFaQ4PwAAAAAAAAAAAAAAAAAAAABku5sbFaQ4PwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGS7mxsVpDg/AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIrMtNQPe1I/AAAAAAAAAABku5sbFaRIPwAAAAAAAAAAAAAAAAAAAABku5sbFaQ4PwAAAAAAAAAAsbubGxWkOD8=\",\"dtype\":\"float64\",\"shape\":[100]}}},\"id\":\"07aa513e-954b-4afa-9340-0d8727dda001\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"de86744f-2028-4782-aae0-151c93494767\",\"type\":\"PanTool\"},{\"attributes\":{\"bottom\":{\"value\":0},\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"left\":{\"field\":\"left\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"right\":{\"field\":\"right\"},\"top\":{\"field\":\"top\"}},\"id\":\"323d06ca-9d86-4e07-b43b-04e911b17240\",\"type\":\"Quad\"},{\"attributes\":{\"bottom\":{\"value\":0},\"fill_color\":{\"value\":\"#1f77b4\"},\"left\":{\"field\":\"left\"},\"line_color\":{\"value\":\"#555555\"},\"right\":{\"field\":\"right\"},\"top\":{\"field\":\"top\"}},\"id\":\"59ebaafe-379a-4b2f-9bb4-8768c912383d\",\"type\":\"Quad\"},{\"attributes\":{},\"id\":\"5dab2f35-e044-4740-bf0c-218666ae1e82\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"3c401b9c-0042-4ead-97d9-0bfad7b09bd4\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"callback\":null},\"id\":\"d82e0a4b-8ddc-4adc-95ed-b74e1a7e6bb4\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"36c36066-e0b1-4568-9ca4-0b8f745ee3a9\",\"type\":\"ResetTool\"},{\"attributes\":{},\"id\":\"ba739ad9-e2a3-4c84-8aba-38d901911a2c\",\"type\":\"SaveTool\"},{\"attributes\":{},\"id\":\"de0923b8-aee1-48a4-b579-fbe05cebd830\",\"type\":\"LinearScale\"},{\"attributes\":{\"callback\":null},\"id\":\"3303a652-8940-4285-adc0-4579dae61c11\",\"type\":\"DataRange1d\"},{\"attributes\":{\"source\":{\"id\":\"07aa513e-954b-4afa-9340-0d8727dda001\",\"type\":\"ColumnDataSource\"}},\"id\":\"c8d30845-5748-4a68-aa7b-b60be21f6377\",\"type\":\"CDSView\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"de86744f-2028-4782-aae0-151c93494767\",\"type\":\"PanTool\"},{\"id\":\"3c401b9c-0042-4ead-97d9-0bfad7b09bd4\",\"type\":\"WheelZoomTool\"},{\"id\":\"36c36066-e0b1-4568-9ca4-0b8f745ee3a9\",\"type\":\"ResetTool\"},{\"id\":\"ba739ad9-e2a3-4c84-8aba-38d901911a2c\",\"type\":\"SaveTool\"}]},\"id\":\"8c03eabc-ec47-4330-9b86-282efab0c6fc\",\"type\":\"Toolbar\"},{\"attributes\":{},\"id\":\"33719ecd-49e8-4f72-a1bd-209b93645843\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"below\":[{\"id\":\"7600af9b-bd74-4165-998c-5e5b19480337\",\"type\":\"LinearAxis\"}],\"left\":[{\"id\":\"692ea610-1ee3-4937-a2e5-bbd4046840bb\",\"type\":\"LinearAxis\"}],\"renderers\":[{\"id\":\"7600af9b-bd74-4165-998c-5e5b19480337\",\"type\":\"LinearAxis\"},{\"id\":\"70e03805-6ea1-4c58-ae73-fd1cbb3a8caf\",\"type\":\"Grid\"},{\"id\":\"692ea610-1ee3-4937-a2e5-bbd4046840bb\",\"type\":\"LinearAxis\"},{\"id\":\"178c5f39-1345-4bdf-8c92-0f1f1ddcdea6\",\"type\":\"Grid\"},{\"id\":\"e2d99b71-6723-4dd9-ad28-fa74637c7c1f\",\"type\":\"GlyphRenderer\"}],\"title\":{\"id\":\"64d44b2e-f0d1-4d8c-a62a-6f839d4d6798\",\"type\":\"Title\"},\"toolbar\":{\"id\":\"8c03eabc-ec47-4330-9b86-282efab0c6fc\",\"type\":\"Toolbar\"},\"toolbar_location\":\"above\",\"x_range\":{\"id\":\"d82e0a4b-8ddc-4adc-95ed-b74e1a7e6bb4\",\"type\":\"DataRange1d\"},\"x_scale\":{\"id\":\"de0923b8-aee1-48a4-b579-fbe05cebd830\",\"type\":\"LinearScale\"},\"y_range\":{\"id\":\"3303a652-8940-4285-adc0-4579dae61c11\",\"type\":\"DataRange1d\"},\"y_scale\":{\"id\":\"6cbe5557-e937-44c6-b8b0-9c3c761579e1\",\"type\":\"LinearScale\"}},\"id\":\"4a061ec2-bb50-4051-b7ed-f044420699ea\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{},\"id\":\"6cbe5557-e937-44c6-b8b0-9c3c761579e1\",\"type\":\"LinearScale\"},{\"attributes\":{\"plot\":null,\"text\":\"Word Positive/Negative Affinity Distribution\"},\"id\":\"64d44b2e-f0d1-4d8c-a62a-6f839d4d6798\",\"type\":\"Title\"},{\"attributes\":{\"data_source\":{\"id\":\"07aa513e-954b-4afa-9340-0d8727dda001\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"59ebaafe-379a-4b2f-9bb4-8768c912383d\",\"type\":\"Quad\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"323d06ca-9d86-4e07-b43b-04e911b17240\",\"type\":\"Quad\"},\"selection_glyph\":null,\"view\":{\"id\":\"c8d30845-5748-4a68-aa7b-b60be21f6377\",\"type\":\"CDSView\"}},\"id\":\"e2d99b71-6723-4dd9-ad28-fa74637c7c1f\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"formatter\":{\"id\":\"33719ecd-49e8-4f72-a1bd-209b93645843\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"4a061ec2-bb50-4051-b7ed-f044420699ea\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"b493dbbf-ed83-45fc-afe4-ec614ccc6adf\",\"type\":\"BasicTicker\"}},\"id\":\"7600af9b-bd74-4165-998c-5e5b19480337\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"b493dbbf-ed83-45fc-afe4-ec614ccc6adf\",\"type\":\"BasicTicker\"},{\"attributes\":{\"plot\":{\"id\":\"4a061ec2-bb50-4051-b7ed-f044420699ea\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"b493dbbf-ed83-45fc-afe4-ec614ccc6adf\",\"type\":\"BasicTicker\"}},\"id\":\"70e03805-6ea1-4c58-ae73-fd1cbb3a8caf\",\"type\":\"Grid\"},{\"attributes\":{\"formatter\":{\"id\":\"5dab2f35-e044-4740-bf0c-218666ae1e82\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"4a061ec2-bb50-4051-b7ed-f044420699ea\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"5273f87a-cfac-4e66-8304-fb786ae4bf00\",\"type\":\"BasicTicker\"}},\"id\":\"692ea610-1ee3-4937-a2e5-bbd4046840bb\",\"type\":\"LinearAxis\"}],\"root_ids\":[\"4a061ec2-bb50-4051-b7ed-f044420699ea\"]},\"title\":\"Bokeh Application\",\"version\":\"0.12.9\"}};\n",
       "    var render_items = [{\"docid\":\"9c093681-8ea0-48d6-9792-daefe7667c18\",\"elementid\":\"299b99f7-9109-4da7-9834-b60522cbb5fe\",\"modelid\":\"4a061ec2-bb50-4051-b7ed-f044420699ea\"}];\n",
       "\n",
       "    root.Bokeh.embed.embed_items(docs_json, render_items);\n",
       "  }\n",
       "\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        embed_document(root);\n",
       "        clearInterval(timer);\n",
       "      }\n",
       "      attempts++;\n",
       "      if (attempts > 100) {\n",
       "        console.log(\"Bokeh: ERROR: Unable to embed document because BokehJS library is missing\")\n",
       "        clearInterval(timer);\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "4a061ec2-bb50-4051-b7ed-f044420699ea"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist, edges = np.histogram(list(map(lambda x:x[1],counts9_all_ratios_log.most_common())), density=True, bins=100, normed=True)\n",
    "\n",
    "p = figure(tools=\"pan,wheel_zoom,reset,save\",\n",
    "           toolbar_location=\"above\",\n",
    "           title=\"Word Positive/Negative Affinity Distribution\")\n",
    "p.quad(top=hist, bottom=0, left=edges[:-1], right=edges[1:], line_color=\"#555555\")\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frequency_frequency = Counter()\n",
    "\n",
    "for word, cnt in total_counts.most_common():\n",
    "    frequency_frequency[cnt] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div class=\"bk-root\">\n",
       "    <div class=\"bk-plotdiv\" id=\"98f30edf-0106-43c3-bcfa-f179d5b021ec\"></div>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    var docs_json = {\"a56b9959-174d-4040-a9ab-05942c20a1b2\":{\"roots\":{\"references\":[{\"attributes\":{},\"id\":\"2cc036f9-6fd2-4b74-a68b-cb506ab20bb5\",\"type\":\"ResetTool\"},{\"attributes\":{\"plot\":null,\"text\":\"The frequency distribution of the words in our corpus\"},\"id\":\"35e28652-7909-400a-8e3e-e8bf54386c03\",\"type\":\"Title\"},{\"attributes\":{},\"id\":\"9adc41e3-efe2-41a3-9a3e-3818eba4a68d\",\"type\":\"SaveTool\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"ab5cd85e-2aaf-4215-95d5-2122765cbc77\",\"type\":\"PanTool\"},{\"id\":\"eae4a4a8-a2c5-4f76-aaee-ce7c9821400d\",\"type\":\"WheelZoomTool\"},{\"id\":\"2cc036f9-6fd2-4b74-a68b-cb506ab20bb5\",\"type\":\"ResetTool\"},{\"id\":\"9adc41e3-efe2-41a3-9a3e-3818eba4a68d\",\"type\":\"SaveTool\"}]},\"id\":\"42db5b22-4bbe-4a91-be3e-7b6cc6e6b5a7\",\"type\":\"Toolbar\"},{\"attributes\":{},\"id\":\"67ce2c9d-6840-42e7-beee-f8fca85474b9\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"source\":{\"id\":\"32861b90-0af1-4300-adba-99580444345a\",\"type\":\"ColumnDataSource\"}},\"id\":\"c833c449-f8ec-45ef-811b-aa8f24a38f81\",\"type\":\"CDSView\"},{\"attributes\":{\"callback\":null,\"column_names\":[\"left\",\"right\",\"top\"],\"data\":{\"left\":{\"__ndarray__\":\"AAAAAAAA8D9I4XoUrnSbQEjhehSucqtA9ihcj4KVtEBI4XoUrnG7QM3MzMzsJsFA9ihcjwKVxEAfhetRGAPIQEjhehQucctAcT0K10PfzkDNzMzMrCbRQOJ6FK633dJA9ihcj8KU1EAK16NwzUvWQB+F61HYAthANDMzM+O52UBI4XoU7nDbQFyPwvX4J91AcT0K1wPf3kDD9ShcB0vgQM3MzMyMJuFA16NwPRIC4kDiehSul93iQOxRuB4dueNA9ihcj6KU5EAAAAAAKHDlQArXo3CtS+ZAFa5H4TIn50AfhetRuALoQClcj8I93uhANDMzM8O56UA+CtejSJXqQEjhehTOcOtAUrgehVNM7EBcj8L12CftQGdmZmZeA+5AcT0K1+Pe7kB7FK5HabrvQMP1KFz3SvBASOF6FLq48EDNzMzMfCbxQFK4HoU/lPFA16NwPQIC8kBcj8L1xG/yQOJ6FK6H3fJAZ2ZmZkpL80DsUbgeDbnzQHE9CtfPJvRA9ihcj5KU9EB7FK5HVQL1QAAAAAAYcPVAhetRuNrd9UAK16NwnUv2QJDC9ShgufZAFa5H4SIn90CamZmZ5ZT3QB+F61GoAvhApHA9Cmtw+EApXI/CLd74QK5H4XrwS/lANDMzM7O5+UC5HoXrdSf6QD4K16M4lfpAw/UoXPsC+0BI4XoUvnD7QM3MzMyA3vtAUrgehUNM/EDXo3A9Brr8QFyPwvXIJ/1A4noUrouV/UBnZmZmTgP+QOxRuB4Rcf5AcT0K19Pe/kD2KFyPlkz/QHsUrkdZuv9AAAAAAA4UAEHD9Shc70oAQYXrUbjQgQBBSOF6FLK4AEEK16Nwk+8AQc3MzMx0JgFBkML1KFZdAUFSuB6FN5QBQRWuR+EYywFB16NwPfoBAkGamZmZ2zgCQVyPwvW8bwJBH4XrUZ6mAkHiehSuf90CQaRwPQphFANBZ2ZmZkJLA0EpXI/CI4IDQexRuB4FuQNBrkfheubvA0FxPQrXxyYEQTMzMzOpXQRB9ihcj4qUBEG5HoXra8sEQXsUrkdNAgVBPgrXoy45BUE=\",\"dtype\":\"float64\",\"shape\":[100]},\"right\":{\"__ndarray__\":\"SOF6FK50m0BI4XoUrnKrQPYoXI+ClbRASOF6FK5xu0DNzMzM7CbBQPYoXI8ClcRAH4XrURgDyEBI4XoULnHLQHE9CtdD385AzczMzKwm0UDiehSut93SQPYoXI/ClNRACtejcM1L1kAfhetR2ALYQDQzMzPjudlASOF6FO5w20Bcj8L1+CfdQHE9CtcD395Aw/UoXAdL4EDNzMzMjCbhQNejcD0SAuJA4noUrpfd4kDsUbgeHbnjQPYoXI+ilORAAAAAAChw5UAK16NwrUvmQBWuR+EyJ+dAH4XrUbgC6EApXI/CPd7oQDQzMzPDuelAPgrXo0iV6kBI4XoUznDrQFK4HoVTTOxAXI/C9dgn7UBnZmZmXgPuQHE9Ctfj3u5AexSuR2m670DD9Shc90rwQEjhehS6uPBAzczMzHwm8UBSuB6FP5TxQNejcD0CAvJAXI/C9cRv8kDiehSuh93yQGdmZmZKS/NA7FG4Hg2580BxPQrXzyb0QPYoXI+SlPRAexSuR1UC9UAAAAAAGHD1QIXrUbja3fVACtejcJ1L9kCQwvUoYLn2QBWuR+EiJ/dAmpmZmeWU90AfhetRqAL4QKRwPQprcPhAKVyPwi3e+ECuR+F68Ev5QDQzMzOzuflAuR6F63Un+kA+CtejOJX6QMP1KFz7AvtASOF6FL5w+0DNzMzMgN77QFK4HoVDTPxA16NwPQa6/EBcj8L1yCf9QOJ6FK6Llf1AZ2ZmZk4D/kDsUbgeEXH+QHE9CtfT3v5A9ihcj5ZM/0B7FK5HWbr/QAAAAAAOFABBw/UoXO9KAEGF61G40IEAQUjhehSyuABBCtejcJPvAEHNzMzMdCYBQZDC9ShWXQFBUrgehTeUAUEVrkfhGMsBQdejcD36AQJBmpmZmds4AkFcj8L1vG8CQR+F61GepgJB4noUrn/dAkGkcD0KYRQDQWdmZmZCSwNBKVyPwiOCA0HsUbgeBbkDQa5H4Xrm7wNBcT0K18cmBEEzMzMzqV0EQfYoXI+KlARBuR6F62vLBEF7FK5HTQIFQT4K16MuOQVBAAAAABBwBUE=\",\"dtype\":\"float64\",\"shape\":[100]},\"top\":{\"__ndarray__\":\"L68EQy2JQj9bwWiLCMC5PuiA8FywKqE+4KtA0ZXjlj7gq0DRleOWPgAAAAAAAAAA4KtA0ZXjhj4AAAAAAAAAAOCrQNGV44Y+AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANqrQNGV44Y+AAAAAAAAAAAAAAAAAAAAANqrQNGV44Y+AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA5qtA0ZXjhj4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAHKxA0ZXjhj4=\",\"dtype\":\"float64\",\"shape\":[100]}}},\"id\":\"32861b90-0af1-4300-adba-99580444345a\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"bottom\":{\"value\":0},\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"left\":{\"field\":\"left\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"right\":{\"field\":\"right\"},\"top\":{\"field\":\"top\"}},\"id\":\"58fd99c0-fdab-4609-8ac3-da234f52fef8\",\"type\":\"Quad\"},{\"attributes\":{},\"id\":\"bc3f5bef-5aca-47d3-99ab-3884c89ae99a\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"plot\":{\"id\":\"fb932b1c-bd76-4f08-96a5-6233865bb6f5\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"cb623350-70c4-41fa-888e-2c8a9e6daff5\",\"type\":\"BasicTicker\"}},\"id\":\"5bfcd00a-f1a4-494c-ac35-df4f7f4538c4\",\"type\":\"Grid\"},{\"attributes\":{\"formatter\":{\"id\":\"67ce2c9d-6840-42e7-beee-f8fca85474b9\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"fb932b1c-bd76-4f08-96a5-6233865bb6f5\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"db8632a2-b5b6-441f-86e8-c46107141c48\",\"type\":\"BasicTicker\"}},\"id\":\"fb875bf1-bc36-421f-a8c6-a4d0d6a09ed3\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"db8632a2-b5b6-441f-86e8-c46107141c48\",\"type\":\"BasicTicker\"},{\"attributes\":{\"dimension\":1,\"plot\":{\"id\":\"fb932b1c-bd76-4f08-96a5-6233865bb6f5\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"db8632a2-b5b6-441f-86e8-c46107141c48\",\"type\":\"BasicTicker\"}},\"id\":\"fb6284be-a0a1-4ad9-9fe4-ee7955619b8b\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"cb623350-70c4-41fa-888e-2c8a9e6daff5\",\"type\":\"BasicTicker\"},{\"attributes\":{\"formatter\":{\"id\":\"bc3f5bef-5aca-47d3-99ab-3884c89ae99a\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"fb932b1c-bd76-4f08-96a5-6233865bb6f5\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"cb623350-70c4-41fa-888e-2c8a9e6daff5\",\"type\":\"BasicTicker\"}},\"id\":\"3370cb9c-5bea-4627-bc19-2840794a9c01\",\"type\":\"LinearAxis\"},{\"attributes\":{\"data_source\":{\"id\":\"32861b90-0af1-4300-adba-99580444345a\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"58860a93-7582-44fd-8494-b58ff1e314dc\",\"type\":\"Quad\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"58fd99c0-fdab-4609-8ac3-da234f52fef8\",\"type\":\"Quad\"},\"selection_glyph\":null,\"view\":{\"id\":\"c833c449-f8ec-45ef-811b-aa8f24a38f81\",\"type\":\"CDSView\"}},\"id\":\"46275799-2746-42d8-bdfc-e04bcb4b5cd3\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"callback\":null},\"id\":\"ccca0a73-ba67-491c-96b2-aef157527ae9\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"eae4a4a8-a2c5-4f76-aaee-ce7c9821400d\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"bottom\":{\"value\":0},\"fill_color\":{\"value\":\"#1f77b4\"},\"left\":{\"field\":\"left\"},\"line_color\":{\"value\":\"#555555\"},\"right\":{\"field\":\"right\"},\"top\":{\"field\":\"top\"}},\"id\":\"58860a93-7582-44fd-8494-b58ff1e314dc\",\"type\":\"Quad\"},{\"attributes\":{},\"id\":\"50aa4a2d-4317-4019-a682-83f6138391cf\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"ab5cd85e-2aaf-4215-95d5-2122765cbc77\",\"type\":\"PanTool\"},{\"attributes\":{},\"id\":\"eb951812-cb57-4788-91e7-a2d5169daa33\",\"type\":\"LinearScale\"},{\"attributes\":{\"below\":[{\"id\":\"3370cb9c-5bea-4627-bc19-2840794a9c01\",\"type\":\"LinearAxis\"}],\"left\":[{\"id\":\"fb875bf1-bc36-421f-a8c6-a4d0d6a09ed3\",\"type\":\"LinearAxis\"}],\"renderers\":[{\"id\":\"3370cb9c-5bea-4627-bc19-2840794a9c01\",\"type\":\"LinearAxis\"},{\"id\":\"5bfcd00a-f1a4-494c-ac35-df4f7f4538c4\",\"type\":\"Grid\"},{\"id\":\"fb875bf1-bc36-421f-a8c6-a4d0d6a09ed3\",\"type\":\"LinearAxis\"},{\"id\":\"fb6284be-a0a1-4ad9-9fe4-ee7955619b8b\",\"type\":\"Grid\"},{\"id\":\"46275799-2746-42d8-bdfc-e04bcb4b5cd3\",\"type\":\"GlyphRenderer\"}],\"title\":{\"id\":\"35e28652-7909-400a-8e3e-e8bf54386c03\",\"type\":\"Title\"},\"toolbar\":{\"id\":\"42db5b22-4bbe-4a91-be3e-7b6cc6e6b5a7\",\"type\":\"Toolbar\"},\"toolbar_location\":\"above\",\"x_range\":{\"id\":\"ccca0a73-ba67-491c-96b2-aef157527ae9\",\"type\":\"DataRange1d\"},\"x_scale\":{\"id\":\"50aa4a2d-4317-4019-a682-83f6138391cf\",\"type\":\"LinearScale\"},\"y_range\":{\"id\":\"22ecc87c-70ba-486e-805a-651480953983\",\"type\":\"DataRange1d\"},\"y_scale\":{\"id\":\"eb951812-cb57-4788-91e7-a2d5169daa33\",\"type\":\"LinearScale\"}},\"id\":\"fb932b1c-bd76-4f08-96a5-6233865bb6f5\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"callback\":null},\"id\":\"22ecc87c-70ba-486e-805a-651480953983\",\"type\":\"DataRange1d\"}],\"root_ids\":[\"fb932b1c-bd76-4f08-96a5-6233865bb6f5\"]},\"title\":\"Bokeh Application\",\"version\":\"0.12.9\"}};\n",
       "    var render_items = [{\"docid\":\"a56b9959-174d-4040-a9ab-05942c20a1b2\",\"elementid\":\"98f30edf-0106-43c3-bcfa-f179d5b021ec\",\"modelid\":\"fb932b1c-bd76-4f08-96a5-6233865bb6f5\"}];\n",
       "\n",
       "    root.Bokeh.embed.embed_items(docs_json, render_items);\n",
       "  }\n",
       "\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        embed_document(root);\n",
       "        clearInterval(timer);\n",
       "      }\n",
       "      attempts++;\n",
       "      if (attempts > 100) {\n",
       "        console.log(\"Bokeh: ERROR: Unable to embed document because BokehJS library is missing\")\n",
       "        clearInterval(timer);\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "fb932b1c-bd76-4f08-96a5-6233865bb6f5"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist, edges = np.histogram(list(map(lambda x:x[1],frequency_frequency.most_common())), density=True, bins=100, normed=True)\n",
    "\n",
    "p = figure(tools=\"pan,wheel_zoom,reset,save\",\n",
    "           toolbar_location=\"above\",\n",
    "           title=\"The frequency distribution of the words in our corpus\")\n",
    "p.quad(top=hist, bottom=0, left=edges[:-1], right=edges[1:], line_color=\"#555555\")\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16781"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_vocab = set()\n",
    "min_count = 20\n",
    "polarity_cutoff = 0.5\n",
    "\n",
    "for i in range(len(X_array)):\n",
    "    for sent in list(str(X_array[i]).split('.')):\n",
    "        for word in sent.split(' '):\n",
    "            if total_counts[word] > min_count:\n",
    "                if counts1_all_ratios_log[word] >= polarity_cutoff or counts1_all_ratios_log[word] <= -polarity_cutoff:\n",
    "                    review_vocab.add(word)\n",
    "                if counts2_all_ratios_log[word] >= polarity_cutoff or counts2_all_ratios_log[word] <= -polarity_cutoff:\n",
    "                    review_vocab.add(word)\n",
    "                if counts3_all_ratios_log[word] >= polarity_cutoff or counts3_all_ratios_log[word] <= -polarity_cutoff:\n",
    "                    review_vocab.add(word)\n",
    "                if counts4_all_ratios_log[word] >= polarity_cutoff or counts4_all_ratios_log[word] <= -polarity_cutoff:\n",
    "                    review_vocab.add(word)\n",
    "                if counts5_all_ratios_log[word] >= polarity_cutoff or counts5_all_ratios_log[word] <= -polarity_cutoff:\n",
    "                    review_vocab.add(word)\n",
    "                if counts6_all_ratios_log[word] >= polarity_cutoff or counts6_all_ratios_log[word] <= -polarity_cutoff:\n",
    "                    review_vocab.add(word)\n",
    "                if counts7_all_ratios_log[word] >= polarity_cutoff or counts7_all_ratios_log[word] <= -polarity_cutoff:\n",
    "                    review_vocab.add(word)\n",
    "                if counts8_all_ratios_log[word] >= polarity_cutoff or counts8_all_ratios_log[word] <= -polarity_cutoff:\n",
    "                    review_vocab.add(word)\n",
    "                if counts9_all_ratios_log[word] >= polarity_cutoff or counts9_all_ratios_log[word] <= -polarity_cutoff:\n",
    "                    review_vocab.add(word)\n",
    "                    \n",
    "len(list(review_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151911"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(counts1_all_ratios_log) +\\\n",
    "len(counts2_all_ratios_log) +\\\n",
    "len(counts3_all_ratios_log) +\\\n",
    "len(counts4_all_ratios_log) +\\\n",
    "len(counts5_all_ratios_log) +\\\n",
    "len(counts6_all_ratios_log) +\\\n",
    "len(counts7_all_ratios_log) +\\\n",
    "len(counts8_all_ratios_log) +\\\n",
    "len(counts9_all_ratios_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "438158"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2index = {}\n",
    "for i, word in enumerate(review_vocab):\n",
    "    word2index[word] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docX = []\n",
    "for i in range(len(X.values)):\n",
    "    sens = []\n",
    "    for sent in list(str(X.values[i][0]).split('.')):\n",
    "        sen = []\n",
    "        for word in sent.strip(' ').split(' '):\n",
    "            if(word in word2index.keys()):\n",
    "                sen.append(word2index[word])\n",
    "        sens.append(sen)\n",
    "    docX.append(sens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docXt = []\n",
    "for i in range(len(X_test.values)):\n",
    "    sens = []\n",
    "    for sent in list(str(X_test.values[i][0]).split('.')):\n",
    "        sen = []\n",
    "        for word in sent.strip(' ').split(' '):\n",
    "            if(word in word2index.keys()):\n",
    "                sen.append(word2index[word])\n",
    "        sens.append(sen)\n",
    "    docXt.append(sens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labelY = df_train['Class'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.array(docX), labelY, test_size = 0.2, random_state= 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2656,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_matmul_bias(seq, weight, bias, nonlinearity=''):\n",
    "    s = None\n",
    "    bias_dim = bias.size()\n",
    "    for i in range(seq.size(0)):\n",
    "        _s = torch.mm(seq[i], weight) \n",
    "        _s_bias = _s + bias.expand(bias_dim[0], _s.size()[0]).transpose(0,1)\n",
    "        if(nonlinearity=='tanh'):\n",
    "            _s_bias = torch.tanh(_s_bias)\n",
    "        _s_bias = _s_bias.unsqueeze(0)\n",
    "        if(s is None):\n",
    "            s = _s_bias\n",
    "        else:\n",
    "            s = torch.cat((s,_s_bias),0)\n",
    "    return s.squeeze()\n",
    "\n",
    "def batch_matmul(seq, weight, nonlinearity=''):\n",
    "    s = None\n",
    "    for i in range(seq.size(0)):\n",
    "        _s = torch.mm(seq[i], weight)\n",
    "        if(nonlinearity=='tanh'):\n",
    "            _s = torch.tanh(_s)\n",
    "        _s = _s.unsqueeze(0)\n",
    "        if(s is None):\n",
    "            s = _s\n",
    "        else:\n",
    "            s = torch.cat((s,_s),0)\n",
    "    return s.squeeze()\n",
    "\n",
    "def attention_mul(rnn_outputs, att_weights):\n",
    "    attn_vectors = None\n",
    "    for i in range(rnn_outputs.size(0)):\n",
    "        h_i = rnn_outputs[i]\n",
    "        a_i = att_weights[i].unsqueeze(1).expand_as(h_i)\n",
    "        h_i = a_i * h_i\n",
    "        h_i = h_i.unsqueeze(0)\n",
    "        if(attn_vectors is None):\n",
    "            attn_vectors = h_i\n",
    "        else:\n",
    "            attn_vectors = torch.cat((attn_vectors,h_i),0)\n",
    "    return torch.sum(attn_vectors, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AttentionWordRNN(nn.Module):\n",
    "    \n",
    "    \n",
    "    def __init__(self, batch_size, num_tokens, embed_size, word_gru_hidden, bidirectional= True):        \n",
    "        \n",
    "        super(AttentionWordRNN, self).__init__()\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.num_tokens = num_tokens\n",
    "        self.embed_size = embed_size\n",
    "        self.word_gru_hidden = word_gru_hidden\n",
    "        self.bidirectional = bidirectional\n",
    "        \n",
    "        self.lookup = nn.Embedding(num_tokens, embed_size)\n",
    "        if bidirectional == True:\n",
    "            self.word_gru = nn.GRU(embed_size, word_gru_hidden, bidirectional= True)\n",
    "            self.weight_W_word = nn.Parameter(torch.Tensor(2* word_gru_hidden,2*word_gru_hidden))\n",
    "            self.bias_word = nn.Parameter(torch.Tensor(2* word_gru_hidden,1))\n",
    "            self.weight_proj_word = nn.Parameter(torch.Tensor(2*word_gru_hidden, 1))\n",
    "        else:\n",
    "            self.word_gru = nn.GRU(embed_size, word_gru_hidden, bidirectional= False)\n",
    "            self.weight_W_word = nn.Parameter(torch.Tensor(word_gru_hidden, word_gru_hidden))\n",
    "            self.bias_word = nn.Parameter(torch.Tensor(word_gru_hidden,1))\n",
    "            self.weight_proj_word = nn.Parameter(torch.Tensor(word_gru_hidden, 1))\n",
    "            \n",
    "        self.softmax_word = nn.Softmax()\n",
    "        self.weight_W_word.data.uniform_(-0.1, 0.1)\n",
    "        self.weight_proj_word.data.uniform_(-0.1,0.1)\n",
    "\n",
    "        \n",
    "    # 权重??? state_word???  \n",
    "    def forward(self, embed, state_word):\n",
    "        # embeddings\n",
    "        embedded = self.lookup(embed)\n",
    "        # word level gru\n",
    "#         print(embedded.size())\n",
    "#         print(state_word.size())\n",
    "        output_word, state_word = self.word_gru(embedded, state_word)\n",
    "#         print output_word.size()\n",
    "        word_squish = batch_matmul_bias(output_word, self.weight_W_word,self.bias_word, nonlinearity='tanh')\n",
    "        word_attn = batch_matmul(word_squish, self.weight_proj_word)\n",
    "#         print(word_attn.size())\n",
    "#         print(word_attn.view(1, -1).transpose(1,0))\n",
    "        word_attn_norm = self.softmax_word(word_attn.transpose(1,0))\n",
    "        word_attn_vectors = attention_mul(output_word, word_attn_norm.transpose(1,0))        \n",
    "        return word_attn_vectors, state_word, word_attn_norm\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        if self.bidirectional == True:\n",
    "            return Variable(torch.zeros(2, self.batch_size, self.word_gru_hidden))\n",
    "        else:\n",
    "            return Variable(torch.zeros(1, self.batch_size, self.word_gru_hidden))\n",
    "    \n",
    "    \n",
    "\n",
    "class AttentionSentRNN(nn.Module):\n",
    "    def __init__(self, batch_size, sent_gru_hidden, word_gru_hidden, n_classes, bidirectional= True):        \n",
    "        \n",
    "        super(AttentionSentRNN, self).__init__()\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.sent_gru_hidden = sent_gru_hidden\n",
    "        self.n_classes = n_classes\n",
    "        self.word_gru_hidden = word_gru_hidden\n",
    "        self.bidirectional = bidirectional\n",
    "        \n",
    "        \n",
    "        if bidirectional == True:\n",
    "            self.sent_gru = nn.GRU(2 * word_gru_hidden, sent_gru_hidden, bidirectional= True)        \n",
    "            self.weight_W_sent = nn.Parameter(torch.Tensor(2* sent_gru_hidden ,2* sent_gru_hidden))\n",
    "            self.bias_sent = nn.Parameter(torch.Tensor(2* sent_gru_hidden,1))\n",
    "            self.weight_proj_sent = nn.Parameter(torch.Tensor(2* sent_gru_hidden, 1))\n",
    "            self.final_linear = nn.Linear(2* sent_gru_hidden, n_classes)\n",
    "        else:\n",
    "            self.sent_gru = nn.GRU(word_gru_hidden, sent_gru_hidden, bidirectional= False)        \n",
    "            self.weight_W_sent = nn.Parameter(torch.Tensor(sent_gru_hidden ,sent_gru_hidden))\n",
    "            self.bias_sent = nn.Parameter(torch.Tensor(sent_gru_hidden,1))\n",
    "            self.weight_proj_sent = nn.Parameter(torch.Tensor(sent_gru_hidden, 1))\n",
    "            self.final_linear = nn.Linear(sent_gru_hidden, n_classes)\n",
    "        self.softmax_sent = nn.Softmax()\n",
    "        self.final_softmax = nn.Softmax()\n",
    "        self.weight_W_sent.data.uniform_(-0.1, 0.1)\n",
    "        self.weight_proj_sent.data.uniform_(-0.1,0.1)\n",
    "        \n",
    "        \n",
    "    def forward(self, word_attention_vectors, state_sent):\n",
    "        print(word_attention_vectors.size())\n",
    "        print(state_sent.size())\n",
    "        output_sent, state_sent = self.sent_gru(word_attention_vectors, state_sent)        \n",
    "        sent_squish = batch_matmul_bias(output_sent, self.weight_W_sent,self.bias_sent, nonlinearity='tanh')\n",
    "        sent_attn = batch_matmul(sent_squish, self.weight_proj_sent)\n",
    "        sent_attn_norm = self.softmax_sent(sent_attn.transpose(1,0))\n",
    "        sent_attn_vectors = attention_mul(output_sent, sent_attn_norm.transpose(1,0))        \n",
    "        # final classifier\n",
    "        final_map = self.final_linear(sent_attn_vectors.squeeze(0))\n",
    "        return F.log_softmax(final_map), state_sent, sent_attn_norm\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        if self.bidirectional == True:\n",
    "            return Variable(torch.zeros(2, self.batch_size, self.sent_gru_hidden))\n",
    "        else:\n",
    "            return Variable(torch.zeros(1, self.batch_size, self.sent_gru_hidden))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert inputs.shape[0] == targets.shape[0]\n",
    "    if shuffle:\n",
    "        indices = np.arange(inputs.shape[0])\n",
    "        np.random.shuffle(indices)\n",
    "        \n",
    "    for start_idx in range(0, inputs.shape[0] - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]\n",
    "        \n",
    "def pad_batch(mini_batch):\n",
    "    mini_batch_size = len(mini_batch)\n",
    "    max_sent_len = int(np.max([len(x) for x in mini_batch]))\n",
    "    max_token_len = int(np.max([len(val) for sublist in mini_batch for val in sublist]))\n",
    "    main_matrix = np.zeros((mini_batch_size, max_sent_len, max_token_len), dtype= np.int)\n",
    "    for i in range(main_matrix.shape[0]):\n",
    "        for j in range(main_matrix.shape[1]):\n",
    "            for k in range(main_matrix.shape[2]):\n",
    "                try:\n",
    "                    main_matrix[i,j,k] = mini_batch[i][j][k]\n",
    "                except IndexError:\n",
    "                    pass\n",
    "    # sen_len * batch * word_vec\n",
    "    return Variable(torch.from_numpy(main_matrix).transpose(0,1))\n",
    "    \n",
    "    \n",
    "def gen_minibatch(tokens, labels, mini_batch_size, shuffle=True):\n",
    "    for token, label in iterate_minibatches(tokens, labels, mini_batch_size, shuffle):\n",
    "        token = pad_batch(token)\n",
    "#         yield token.cuda(), Variable(torch.from_numpy(label), requires_grad= False).cuda()  \n",
    "        yield token, Variable(torch.from_numpy(label), requires_grad= False) \n",
    "        \n",
    "\n",
    "def get_predictions(val_tokens, word_attn_model, sent_attn_model):\n",
    "    max_sents, batch_size, max_tokens = val_tokens.size()\n",
    "#     state_word = word_attn_model.init_hidden().cuda()\n",
    "    state_word = word_attn_model.init_hidden()\n",
    "    \n",
    "#     state_sent = sent_attn_model.init_hidden().cuda()  \n",
    "    state_sent = sent_attn_model.init_hidden()  \n",
    "    \n",
    "    s = None\n",
    "    for i in range(max_sents):\n",
    "        _s, state_word, _ = word_attn_model(val_tokens[i,:,:].transpose(0,1), state_word)\n",
    "        if(s is None):\n",
    "            s = _s\n",
    "        else:\n",
    "            s = torch.cat((s,_s),0)            \n",
    "    y_pred, state_sent, _ = sent_attn_model(s, state_sent)    \n",
    "    return y_pred\n",
    "\n",
    "def test_accuracy_mini_batch(tokens, labels, word_attn, sent_attn):\n",
    "    y_pred = get_predictions(tokens, word_attn, sent_attn)\n",
    "    _, y_pred = torch.max(y_pred, 1)\n",
    "    correct = np.ndarray.flatten(y_pred.data.cpu().numpy())\n",
    "    labels = np.ndarray.flatten(labels.data.cpu().numpy())\n",
    "    num_correct = sum(correct == labels)\n",
    "    return float(num_correct) / len(correct)\n",
    "        \n",
    "def test_accuracy_full_batch(tokens, labels, mini_batch_size, word_attn, sent_attn):\n",
    "    p = []\n",
    "    l = []\n",
    "    g = gen_minibatch(tokens, labels, mini_batch_size)\n",
    "    for token, label in g:\n",
    "#         y_pred = get_predictions(token.cuda(), word_attn, sent_attn)\n",
    "        y_pred = get_predictions(token, word_attn, sent_attn)\n",
    "        \n",
    "        _, y_pred = torch.max(y_pred, 1)\n",
    "        p.append(np.ndarray.flatten(y_pred.data.cpu().numpy()))\n",
    "        l.append(np.ndarray.flatten(label.data.cpu().numpy()))\n",
    "    p = [item for sublist in p for item in sublist]\n",
    "    l = [item for sublist in l for item in sublist]\n",
    "    p = np.array(p)\n",
    "    l = np.array(l)\n",
    "    num_correct = sum(p == l)\n",
    "    return float(num_correct)/ len(p)\n",
    "    \n",
    "def check_val_loss(val_tokens, val_labels, mini_batch_size, word_attn_model, sent_attn_model):\n",
    "    val_loss = []\n",
    "    for token, label in iterate_minibatches(val_tokens, val_labels, mini_batch_size, shuffle= True):\n",
    "#         val_loss.append(test_data(pad_batch(token).cuda(), Variable(torch.from_numpy(label), requires_grad= False).cuda(), \n",
    "#                                   word_attn_model, sent_attn_model))\n",
    "        val_loss.append(test_data(pad_batch(token), Variable(torch.from_numpy(label), requires_grad= False), \n",
    "                                  word_attn_model, sent_attn_model))\n",
    "    return np.mean(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_data(mini_batch, targets, word_attn_model, sent_attn_model, word_optimizer, sent_optimizer, criterion):\n",
    "#     state_word = word_attn_model.init_hidden().cuda()\n",
    "    state_word = word_attn_model.init_hidden()\n",
    "    \n",
    "#     \n",
    "#     state_sent = sent_attn_model.init_hidden().cuda()\n",
    "    state_sent = sent_attn_model.init_hidden()\n",
    "    \n",
    "    max_sents, batch_size, max_tokens = mini_batch.size()\n",
    "    word_optimizer.zero_grad()\n",
    "    sent_optimizer.zero_grad()\n",
    "    s = None\n",
    "    for i in range(max_sents):\n",
    "        _s, state_word, _ = word_attn_model(mini_batch[i,:,:].transpose(0,1), state_word)\n",
    "        _s = _s.unsqueeze(0)\n",
    "        if(s is None):\n",
    "            s = _s\n",
    "        else:\n",
    "            s = torch.cat((s,_s),0)            \n",
    "    y_pred, state_sent, _ = sent_attn_model(s, state_sent)\n",
    "#     loss = criterion(y_pred.cuda(), targets) \n",
    "    loss = criterion(y_pred, targets) \n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    word_optimizer.step()\n",
    "    sent_optimizer.step()\n",
    "    \n",
    "    return loss.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_attn = AttentionWordRNN(\n",
    "    batch_size=2, \n",
    "    num_tokens=16781, \n",
    "    embed_size=64,                    \n",
    "    word_gru_hidden=32, \n",
    "    bidirectional= False\n",
    ")\n",
    "\n",
    "sent_attn = AttentionSentRNN(\n",
    "    batch_size=2, \n",
    "    sent_gru_hidden=32, \n",
    "    word_gru_hidden=32,             \n",
    "    n_classes=9, \n",
    "    bidirectional= False\n",
    ")\n",
    "\n",
    "learning_rate = 1e-1\n",
    "word_optmizer = optim.Adam(word_attn.parameters(), lr=learning_rate)\n",
    "sent_optimizer = optim.Adam(sent_attn.parameters(), lr=learning_rate)\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def as_minutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (as_minutes(s), as_minutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# word_attn.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sent_attn.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_early_stopping(\n",
    "    mini_batch_size,\n",
    "    X_train, y_train,\n",
    "    X_test, y_test,\n",
    "    word_attn_model, sent_attn_model,\n",
    "    word_attn_optimizer, sent_attn_optimizer,\n",
    "    loss_criterion, num_epoch,\n",
    "    print_val_loss_every = 1000,\n",
    "    print_loss_every = 50\n",
    "):\n",
    "    start = time.time()\n",
    "    loss_full = []\n",
    "    loss_epoch = []\n",
    "    accuracy_epoch = []\n",
    "    loss_smooth = []\n",
    "    accuracy_full = []\n",
    "    epoch_counter = 0\n",
    "    g = gen_minibatch(X_train, y_train, mini_batch_size)\n",
    "    \n",
    "    for i in range(1, num_epoch + 1):\n",
    "        try:\n",
    "            tokens, labels = next(g)\n",
    "            loss = train_data(tokens, labels, word_attn_model, sent_attn_model, word_attn_optimizer, sent_attn_optimizer, loss_criterion)\n",
    "            acc = test_accuracy_mini_batch(tokens, labels, word_attn_model, sent_attn_model)\n",
    "            accuracy_full.append(acc)\n",
    "            accuracy_epoch.append(acc)\n",
    "            loss_full.append(loss)\n",
    "            loss_epoch.append(loss)\n",
    "            # print loss every n passes\n",
    "            if i % print_loss_every == 0:\n",
    "                print('Loss at %d minibatches, %d epoch,(%s) is %f' %(i, epoch_counter, timeSince(start, i / num_epoch), np.mean(loss_epoch)))\n",
    "                print('Accuracy at %d minibatches is %f' % (i, np.mean(accuracy_epoch)))\n",
    "            # check validation loss every n passes\n",
    "            if i % print_val_loss_every == 0:\n",
    "                val_loss = check_val_loss(X_test, y_test, mini_batch_size, word_attn_model, sent_attn_model)\n",
    "                print('Average training loss at this epoch..minibatch..%d..is %f' % (i, np.mean(loss_epoch)))\n",
    "                print('Validation loss after %d passes is %f' %(i, val_loss))\n",
    "                if val_loss > np.mean(loss_full):\n",
    "                    print('Validation loss is higher than training loss at %d is %f , stopping training!' % (i, val_loss))\n",
    "                    print('Average training loss at %d is %f' % (i, np.mean(loss_full)))\n",
    "            \n",
    "        except StopIteration:\n",
    "            epoch_counter += 1\n",
    "            print('Reached %d epocs' % epoch_counter)\n",
    "            print('i %d' % i)\n",
    "            g = gen_minibatch(X_train, y_train, mini_batch_size)\n",
    "            loss_epoch = []\n",
    "            accuracy_epoch = []\n",
    "        \n",
    "    return loss_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2537, 2, 32])\n",
      "torch.Size([1, 2, 32])\n"
     ]
    }
   ],
   "source": [
    "loss_full= train_early_stopping(2, \n",
    "    X_train, y_train, \n",
    "    X_test, y_test, \n",
    "    word_attn, sent_attn,\n",
    "    word_optmizer, sent_optimizer, \n",
    "    criterion, 5, 5, 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
