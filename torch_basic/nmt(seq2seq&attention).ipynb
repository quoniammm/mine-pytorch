{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "# 导入 SRU\n",
    "from cuda_functional import SRU, SRUCell\n",
    "\n",
    "import re\n",
    "import tqdm\n",
    "import jieba\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.数据处理部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "USE_CUDA = True\n",
    "path = './data/cmn-eng/'\n",
    "\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "MAX_LENGTH = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def isChinese(sen):\n",
    "    zhPattern = re.compile(u'[\\u4e00-\\u9fa5]+')\n",
    "    return zhPattern.search(sen)\n",
    "# 简化句子 便于处理\n",
    "def normalize_string(s):\n",
    "    s = re.sub(r\"[!！？.()（）\"\"?。“”，,']\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2 # Count SOS and EOS\n",
    "      \n",
    "    def index_words(self, sentence):\n",
    "        sen_list = []\n",
    "        if isChinese(sentence):\n",
    "            sen_list = jieba.cut(sentence)\n",
    "        else:\n",
    "            sen_list = sentence.split(' ')\n",
    "            \n",
    "        for word in sen_list:\n",
    "            self.index_word(word)\n",
    "\n",
    "    def index_word(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_sen(path, lang1, lang2, reverse=False):\n",
    "    with open(path + '{}-{}.txt'.format(lang1, lang2)) as f:\n",
    "        lines = f.readlines()\n",
    "        pairs = []\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if reverse:\n",
    "                line = line.split('\\t')\n",
    "                line.reverse()\n",
    "                line = \"\\t\".join(line)\n",
    "                \n",
    "            pair = [normalize_string(sen) for sen in line.split('\\t')]\n",
    "            pairs.append(pair)\n",
    "        \n",
    "        if reverse:\n",
    "            input_lang = Lang(lang2)\n",
    "            output_lang = Lang(lang1) \n",
    "        else:\n",
    "            input_lang = Lang(lang1)            \n",
    "            output_lang = Lang(lang2)   \n",
    "            \n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read lines......\n",
      "Trimmed  to 19056 sentence pairs\n",
      "Indexing words......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 0.718 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Their house is being remodeled ', '他們的房子正在裝潢 ']\n",
      "['We sometimes swim in the lake ', '我們偶爾在湖裡游泳 ']\n",
      "['They are my brothers ', '他们是我的兄弟 ']\n",
      "['You look as healthy as ever ', '你看起來健康如昔 ']\n",
      "['Dad bought me a camera ', '爸爸给我买了一个照相机 ']\n"
     ]
    }
   ],
   "source": [
    "def data_preprocess(path, lang1, lang2, reverse=False):\n",
    "    print(\"Read lines......\")\n",
    "    input_lang, output_lang, pairs = read_sen(path, lang1, lang2, reverse)\n",
    "    print(\"Trimmed  to {} sentence pairs\".format(len(pairs)))\n",
    "    \n",
    "    print(\"Indexing words......\")\n",
    "    for pair in pairs:\n",
    "        input_lang.index_words(pair[0])\n",
    "        output_lang.index_words(pair[1])\n",
    "    \n",
    "    return input_lang, output_lang, pairs\n",
    "    \n",
    "input_lang, output_lang, pairs = data_preprocess(path, 'eng', 'cmn')\n",
    "for i in range(5):\n",
    "    print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.pytorch 搭建模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2.1.数据部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sen's index\n",
    "def ixs_from_sen(lang, sen):\n",
    "    if isChinese(lang):\n",
    "        sen = jieba.cut('')\n",
    "    else:\n",
    "        sen = sen.split(' ')\n",
    "        \n",
    "    return [lang.word2index[word] for word in sen]\n",
    "\n",
    "def var_from_sen(lang, sen):\n",
    "    ixs = ixs_from_sen(lang, sen)\n",
    "    ixs.append(EOS_token)\n",
    "    var = Variable(torch.LongTensor(ixs).view(-1, 1))\n",
    "    if USE_CUDA: \n",
    "        var = var.cuda()\n",
    "    \n",
    "    return var\n",
    "    \n",
    "\n",
    "def var_from_pair(pair):\n",
    "    input_variable = var_from_sen(input_lang, pair[0])\n",
    "    input_variable = var_from_sen(output_lang, pair[1])\n",
    "\n",
    "    return (input_variable, output_variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2.2.模型搭建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 编码层\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers)\n",
    "    \n",
    "    def forward(self, X, hidden):\n",
    "        seq_len = len(X)\n",
    "        # 为什么 embedding 输入只有 X,不是应该还有 hidden_size\n",
    "        embedded = self.embedding(X).view(seq_len, 1, -1)\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        hidden = Variable(torch.zeros(self.n_layers, 1, self.hidden_size))\n",
    "        if USE_CUDA: hidden = hidden.cuda()\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `class` not found.\n",
      "Object `class` not found.\n",
      "Object `class` not found.\n"
     ]
    }
   ],
   "source": [
    "# 带有注意力机制的解码层\n",
    "\n",
    "## 原始的 decoder with attention\n",
    "?class BahdanauAttnDecoderRNN(nn.Module):\n",
    "## attenion layer\n",
    "?class Attn(nn.Module):\n",
    "## 改进的 decoder with attention\n",
    "?class AttnDecoderRNN(nn.MOdule):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2.3.训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2.4.模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    pass\n",
    "\n",
    "def evaluate_randomly():\n",
    "    pass\n",
    "\n",
    "# 可视化 Attention\n",
    "def show_attention():\n",
    "    pass\n",
    "\n",
    "def eva_and_show_attention():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2.5.模型提高"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
