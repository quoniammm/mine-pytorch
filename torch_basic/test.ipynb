{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read lines......\n",
      "input_lang is 2\n",
      "Trimmed  to 19056 sentence pairs\n",
      "Indexing words......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 0.745 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['My baggage is missing ', '我的行李丢了 ']\n",
      "['He has long hair ', '他有長頭髮 ']\n",
      "['Tom is used to getting up early ', '汤姆习惯早起 ']\n",
      "['Do it somewhere else ', '到别处去做 ']\n",
      "['You can t keep a secret ', '你不能有秘密 ']\n",
      "EncoderRNN (\n",
      "  (embedding): Embedding(10, 10)\n",
      "  (gru): GRU(10, 10, num_layers=2, batch_first=True)\n",
      ")\n",
      "AttnDecoderRNN (\n",
      "  (embedding): Embedding(10, 10)\n",
      "  (gru): GRU(20, 10, num_layers=2, batch_first=True, dropout=0.1)\n",
      "  (out): Linear (20 -> 10)\n",
      "  (attn): Attn (\n",
      "    (attn): Linear (10 -> 10)\n",
      "  )\n",
      ")\n",
      "Variable containing:\n",
      "(0 ,.,.) = \n",
      "  0.3340  0.3327  0.3334\n",
      "[torch.FloatTensor of size 1x1x3]\n",
      "\n",
      "Variable containing:\n",
      "(0 ,.,.) = \n",
      "  0.3335  0.3329  0.3336\n",
      "[torch.FloatTensor of size 1x1x3]\n",
      "\n",
      "Variable containing:\n",
      "(0 ,.,.) = \n",
      "  0.3354  0.3302  0.3344\n",
      "[torch.FloatTensor of size 1x1x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "\n",
    "import re\n",
    "import time\n",
    "import jieba\n",
    "import random\n",
    "import math\n",
    "import string\n",
    "\n",
    "#%%\n",
    "# # 1.数据处理部分\n",
    "USE_CUDA = False\n",
    "path = 'data/cmn-eng/'\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "MAX_LENGTH = 10\n",
    "\n",
    "def isChinese(sen):\n",
    "    zhPattern = re.compile(u'[\\u4e00-\\u9fa5]+')\n",
    "    return zhPattern.search(sen)\n",
    "# 简化句子 便于处理\n",
    "def normalize_string(s):\n",
    "    s = re.sub(r\"[!！？.()（）\"\"?。“”，,']\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2 # Count SOS and EOS\n",
    "      \n",
    "    def index_words(self, sentence):\n",
    "        sen_list = []\n",
    "        if isChinese(sentence):\n",
    "            sen_list = jieba.cut(sentence)\n",
    "        else:\n",
    "            sen_list = sentence.split(' ')\n",
    "            \n",
    "        for word in sen_list:\n",
    "            self.index_word(word)\n",
    "\n",
    "    def index_word(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "\n",
    "def read_sen(path, lang1, lang2, reverse=False):\n",
    "    with open(path + '{}-{}.txt'.format(lang1, lang2)) as f:\n",
    "        lines = f.readlines()\n",
    "        pairs = []\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if reverse:\n",
    "                line = line.split('\\t')\n",
    "                line.reverse()\n",
    "                line = \"\\t\".join(line)\n",
    "                \n",
    "            pair = [normalize_string(sen) for sen in line.split('\\t')]\n",
    "            pairs.append(pair)\n",
    "        \n",
    "        if reverse:\n",
    "            input_lang = Lang(lang2)\n",
    "            output_lang = Lang(lang1) \n",
    "        else:\n",
    "            input_lang = Lang(lang1)            \n",
    "            output_lang = Lang(lang2)   \n",
    "\n",
    "        print(\"input_lang is {}\".format(input_lang.n_words))\n",
    "            \n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "def data_preprocess(path, lang1, lang2, reverse=False):\n",
    "    print(\"Read lines......\")\n",
    "    input_lang, output_lang, pairs = read_sen(path, lang1, lang2, reverse)\n",
    "    print(\"Trimmed  to {} sentence pairs\".format(len(pairs)))\n",
    "    \n",
    "    print(\"Indexing words......\")\n",
    "    for pair in pairs:\n",
    "        input_lang.index_words(pair[0])\n",
    "        output_lang.index_words(pair[1])\n",
    "    \n",
    "    return input_lang, output_lang, pairs\n",
    "    \n",
    "input_lang, output_lang, pairs = data_preprocess(path, 'eng', 'cmn')\n",
    "for i in range(5):\n",
    "    print(random.choice(pairs))\n",
    "\n",
    "#%%\n",
    "# # 2.pytorch 搭建模型\n",
    "# ## 2.1.数据部分\n",
    "def indexes_from_sentence(lang, sen):\n",
    "    if isChinese(sen):\n",
    "        sen = jieba.cut('')\n",
    "    else:\n",
    "        sen = sen.split(' ')\n",
    "        \n",
    "    return [lang.word2index[word] for word in sen]\n",
    "\n",
    "def variable_from_sentence(lang, sen):\n",
    "    ixs = indexes_from_sentence(lang, sen)\n",
    "    ixs.append(EOS_token)\n",
    "    var = Variable(torch.LongTensor(ixs).view(-1, 1))\n",
    "    if USE_CUDA: \n",
    "        var = var.cuda()\n",
    "    \n",
    "    return var\n",
    "    \n",
    "\n",
    "def variables_from_pair(pair):\n",
    "    input_variable = variable_from_sentence(input_lang, pair[0])\n",
    "    output_variable = variable_from_sentence(output_lang, pair[1])\n",
    "\n",
    "    return (input_variable, output_variable)\n",
    "\n",
    "\n",
    "#%%\n",
    "# ## 2.2.模型搭建\n",
    "# 编码层\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, batch_first=True)\n",
    "\n",
    "    def forward(self, word_inputs, hidden):\n",
    "        seq_len = len(word_inputs)\n",
    "        embedded = self.embedding(word_inputs).view(1, seq_len, -1)\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        hidden = Variable(torch.zeros(self.n_layers, 1, self.hidden_size))\n",
    "        if USE_CUDA: hidden = hidden.cuda()\n",
    "        return hidden\n",
    "# Attn 层\n",
    "class Attn(nn.Module):\n",
    "    def __init__(self, method, hidden_size):\n",
    "        super(Attn, self).__init__()\n",
    "\n",
    "        self.method = method\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        if self.method == 'general':\n",
    "            self.attn = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "\n",
    "        # else self.method = 'concat':\n",
    "        #     self.attn = \n",
    "        #     self.other = \n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        seq_len = encoder_outputs.size()[1]\n",
    "\n",
    "        attn_energies = Variable(torch.zeros(seq_len))\n",
    "        if USE_CUDA:\n",
    "            attn_energies.cuda()\n",
    "\n",
    "        for i in range(seq_len):\n",
    "            attn_energies[i] = self.score(hidden, encoder_outputs[0][i])\n",
    "\n",
    "        return F.softmax(attn_energies).unsqueeze(0).unsqueeze(0)\n",
    "    \n",
    "    def score(self, hidden, encoder_output):\n",
    "        if self.method == 'general':\n",
    "            energy = self.attn(encoder_output)\n",
    "            # 矩阵维度有些不理解\n",
    "            energy = torch.dot(hidden.view(-1), energy.view(-1))\n",
    "            return energy\n",
    "# 改进的解码层\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, attn_model, hidden_size, output_size, n_layers=1, dropout_p=.1):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        # 定义参数\n",
    "        self.attn_model = attn_model\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        # 定义层\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size * 2, hidden_size, n_layers, dropout=dropout_p, batch_first=True)\n",
    "        # 为什么乘 2\n",
    "        self.out = nn.Linear(hidden_size * 2, output_size)\n",
    "\n",
    "        if attn_model != 'none':\n",
    "            self.attn = Attn(attn_model, hidden_size)\n",
    "\n",
    "    def forward(self, word_input, last_context, last_hidden, encoder_outputs):\n",
    "        word_embedded = self.embedding(word_input).view(1, 1, -1)\n",
    "\n",
    "        rnn_input = torch.cat((word_embedded, last_context.unsqueeze(0)), 2)\n",
    "        rnn_output, hidden = self.gru(rnn_input, last_hidden)\n",
    "\n",
    "        attn_weights = self.attn(rnn_output.squeeze(0), encoder_outputs)\n",
    "        context = attn_weights.bmm(encoder_outputs)\n",
    "        # print(\"context size is {}\".format(context.size()))\n",
    "        rnn_output = rnn_output.squeeze(1)\n",
    "        context =  context.squeeze(0)\n",
    "        # print(\"context size is {}\".format(context.size()))        \n",
    "        # 这块还有点不理解\n",
    "        output = F.log_softmax(self.out(torch.cat((rnn_output, context), 1)))\n",
    "\n",
    "        return output, context, hidden, attn_weights\n",
    "\n",
    "#%%\n",
    "# 对模型进行测试\n",
    "encoder_test = EncoderRNN(10, 10, 2)\n",
    "decoder_test = AttnDecoderRNN('general', 10, 10, 2)\n",
    "print(encoder_test)\n",
    "print(decoder_test)\n",
    "\n",
    "encoder_hidden = encoder_test.init_hidden()\n",
    "word_input = Variable(torch.LongTensor([1, 2, 3]))\n",
    "if USE_CUDA:\n",
    "    encoder_test.cuda()\n",
    "    word_input = word_input.cuda()\n",
    "encoder_outputs, encoder_hidden = encoder_test(word_input, encoder_hidden)\n",
    "\n",
    "word_inputs = Variable(torch.LongTensor([1, 2, 3]))\n",
    "decoder_attns = torch.zeros(1, 3, 3)\n",
    "decoder_hidden = encoder_hidden\n",
    "decoder_context = Variable(torch.zeros(1, decoder_test.hidden_size))\n",
    "\n",
    "if USE_CUDA:\n",
    "    decoder_test.cuda()\n",
    "    word_inputs = word_inputs.cuda()\n",
    "    decoder_context = decoder_context.cuda()\n",
    "\n",
    "for i in range(3):\n",
    "    decoder_output, decoder_context, decoder_hidden, decoder_attn = decoder_test(word_inputs[i], decoder_context, decoder_hidden, encoder_outputs)\n",
    "#     print(decoder_output.size(), decoder_hidden.size(), decoder_attn.size())\n",
    "    print(decoder_attn)\n",
    "    decoder_attns[0, i] = decoder_attn.squeeze(0).cpu().data\n",
    "#     print(decoder_attns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EncoderRNN (\n",
      "  (embedding): Embedding(10, 10)\n",
      "  (gru): GRU(10, 10, num_layers=2, batch_first=True)\n",
      ")\n",
      "AttnDecoderRNN (\n",
      "  (embedding): Embedding(10, 10)\n",
      "  (gru): GRU(20, 10, num_layers=2, batch_first=True, dropout=0.1)\n",
      "  (out): Linear (20 -> 10)\n",
      "  (attn): Attn (\n",
      "    (attn): Linear (10 -> 10)\n",
      "  )\n",
      ")\n",
      "\n",
      "(0 ,.,.) = \n",
      "  0.2492  0.2507  0.2506  0.2495\n",
      "  0.0000  0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  0.0000\n",
      "[torch.FloatTensor of size 1x5x4]\n",
      "\n",
      "\n",
      "(0 ,.,.) = \n",
      "  0.2492  0.2507  0.2506  0.2495\n",
      "  0.2474  0.2504  0.2514  0.2509\n",
      "  0.0000  0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  0.0000\n",
      "[torch.FloatTensor of size 1x5x4]\n",
      "\n",
      "\n",
      "(0 ,.,.) = \n",
      "  0.2492  0.2507  0.2506  0.2495\n",
      "  0.2474  0.2504  0.2514  0.2509\n",
      "  0.2469  0.2492  0.2517  0.2521\n",
      "  0.0000  0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  0.0000\n",
      "[torch.FloatTensor of size 1x5x4]\n",
      "\n",
      "\n",
      "(0 ,.,.) = \n",
      "  0.2492  0.2507  0.2506  0.2495\n",
      "  0.2474  0.2504  0.2514  0.2509\n",
      "  0.2469  0.2492  0.2517  0.2521\n",
      "  0.2478  0.2496  0.2513  0.2513\n",
      "  0.0000  0.0000  0.0000  0.0000\n",
      "[torch.FloatTensor of size 1x5x4]\n",
      "\n",
      "\n",
      "(0 ,.,.) = \n",
      "  0.2492  0.2507  0.2506  0.2495\n",
      "  0.2474  0.2504  0.2514  0.2509\n",
      "  0.2469  0.2492  0.2517  0.2521\n",
      "  0.2478  0.2496  0.2513  0.2513\n",
      "  0.2509  0.2516  0.2496  0.2480\n",
      "[torch.FloatTensor of size 1x5x4]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoder_test = EncoderRNN(10, 10, 2)\n",
    "decoder_test = AttnDecoderRNN('general', 10, 10, 2)\n",
    "\n",
    "print(encoder_test)\n",
    "print(decoder_test)\n",
    "\n",
    "encoder_hidden = encoder_test.init_hidden()\n",
    "word_input = Variable(torch.LongTensor([1, 9, 3, 4]))\n",
    "\n",
    "if USE_CUDA:\n",
    "    encoder_test.cuda()\n",
    "    word_input.cuda()\n",
    "\n",
    "encoder_outputs, encoder_hidden = encoder_test(word_input, encoder_hidden)\n",
    "\n",
    "word_inputs = Variable(torch.LongTensor([1, 2, 6, 6, 8]))\n",
    "# 不是很理解\n",
    "decoder_attns = torch.zeros(1, 5, 4)\n",
    "decoder_hidden = encoder_hidden \n",
    "decoder_context = Variable(torch.zeros(1, decoder_test.hidden_size))\n",
    "\n",
    "if USE_CUDA:\n",
    "    decoder_test.cuda()\n",
    "    word_inputs = word_inputs.cuda()\n",
    "    decoder_context = decoder_context.cuda()\n",
    "\n",
    "for i in range(5):\n",
    "    decoder_output, decoder_context, deocder_hidden, decoder_attn = decoder_test(word_inputs[i], decoder_context, decoder_hidden, encoder_outputs)\n",
    "    decoder_attns[0, i] = decoder_attn.squeeze(0).cpu().data\n",
    "    print(decoder_attns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_inputs = Variable(torch.LongTensor([1, 2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 3\n",
      "[torch.LongTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(word_inputs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       "   539\n",
       "   313\n",
       "  1287\n",
       "    77\n",
       "  3013\n",
       "     3\n",
       "     1\n",
       " [torch.LongTensor of size 7x1], Variable containing:\n",
       "  1\n",
       " [torch.LongTensor of size 1x1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variables_from_pair(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read lines......\n",
      "Trimmed  to 19056 sentence pairs\n",
      "Indexing words......\n",
      "['What should they do in this situation ', '在这种情况下 他们该做什么 ']\n",
      "['I heard you were injured trying to help Tom ', '我听说你在试图帮助汤姆的时候受伤了 ']\n",
      "['I d like some more bread  please ', '我想再要些麵包 謝謝 ']\n",
      "['That pasture is ten acres ', '那個牧場有十英畝大 ']\n",
      "['Do you have any idea when the bank closes ', '你知道银行什么时候关门吗 ']\n",
      "\n",
      "(0 ,.,.) = \n",
      "  0.2494  0.2508  0.2547  0.2451\n",
      "  0.0000  0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  0.0000\n",
      "[torch.FloatTensor of size 1x5x4]\n",
      "\n",
      "\n",
      "(0 ,.,.) = \n",
      "  0.2494  0.2508  0.2547  0.2451\n",
      "  0.2529  0.2526  0.2529  0.2415\n",
      "  0.0000  0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  0.0000\n",
      "[torch.FloatTensor of size 1x5x4]\n",
      "\n",
      "\n",
      "(0 ,.,.) = \n",
      "  0.2494  0.2508  0.2547  0.2451\n",
      "  0.2529  0.2526  0.2529  0.2415\n",
      "  0.2489  0.2520  0.2511  0.2480\n",
      "  0.0000  0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  0.0000\n",
      "[torch.FloatTensor of size 1x5x4]\n",
      "\n",
      "\n",
      "(0 ,.,.) = \n",
      "  0.2494  0.2508  0.2547  0.2451\n",
      "  0.2529  0.2526  0.2529  0.2415\n",
      "  0.2489  0.2520  0.2511  0.2480\n",
      "  0.2489  0.2519  0.2512  0.2480\n",
      "  0.0000  0.0000  0.0000  0.0000\n",
      "[torch.FloatTensor of size 1x5x4]\n",
      "\n",
      "\n",
      "(0 ,.,.) = \n",
      "  0.2494  0.2508  0.2547  0.2451\n",
      "  0.2529  0.2526  0.2529  0.2415\n",
      "  0.2489  0.2520  0.2511  0.2480\n",
      "  0.2489  0.2519  0.2512  0.2480\n",
      "  0.2504  0.2519  0.2550  0.2426\n",
      "[torch.FloatTensor of size 1x5x4]\n",
      "\n",
      "decoder is torch.Size([1, 13152])\n",
      "targget is torch.Size([1, 1])\n",
      "decoder is torch.Size([1, 13152])\n",
      "targget is torch.Size([1, 1])\n",
      "decoder is torch.Size([1, 13152])\n",
      "targget is torch.Size([1, 1])\n",
      "decoder is torch.Size([1, 13152])\n",
      "targget is torch.Size([1, 1])\n",
      "decoder is torch.Size([1, 13152])\n",
      "targget is torch.Size([1, 1])\n",
      "decoder is torch.Size([1, 13152])\n",
      "targget is torch.Size([1, 1])\n",
      "decoder is torch.Size([1, 13152])\n",
      "targget is torch.Size([1, 1])\n",
      "decoder is torch.Size([1, 13152])\n",
      "targget is torch.Size([1, 1])\n",
      "decoder is torch.Size([1, 13152])\n",
      "targget is torch.Size([1, 1])\n",
      "decoder is torch.Size([1, 13152])\n",
      "targget is torch.Size([1, 1])\n",
      "decoder is torch.Size([1, 13152])\n",
      "targget is torch.Size([1, 1])\n",
      "decoder is torch.Size([1, 13152])\n",
      "targget is torch.Size([1, 1])\n",
      "decoder is torch.Size([1, 13152])\n",
      "targget is torch.Size([1, 1])\n",
      "decoder is torch.Size([1, 13152])\n",
      "targget is torch.Size([1, 1])\n",
      "decoder is torch.Size([1, 13152])\n",
      "targget is torch.Size([1, 1])\n",
      "decoder is torch.Size([1, 13152])\n",
      "targget is torch.Size([1, 1])\n",
      "decoder is torch.Size([1, 13152])\n",
      "targget is torch.Size([1, 1])\n",
      "decoder is torch.Size([1, 13152])\n",
      "targget is torch.Size([1, 1])\n",
      "decoder is torch.Size([1, 13152])\n",
      "targget is torch.Size([1, 1])\n",
      "decoder is torch.Size([1, 13152])\n",
      "targget is torch.Size([1, 1])\n",
      "decoder is torch.Size([1, 13152])\n",
      "targget is torch.Size([1, 1])\n",
      "decoder is torch.Size([1, 13152])\n",
      "targget is torch.Size([1, 1])\n",
      "decoder is torch.Size([1, 13152])\n",
      "targget is torch.Size([1, 1])\n",
      "decoder is torch.Size([1, 13152])\n",
      "targget is torch.Size([1, 1])\n",
      "decoder is torch.Size([1, 13152])\n",
      "targget is torch.Size([1, 1])\n",
      "decoder is torch.Size([1, 13152])\n",
      "targget is torch.Size([1, 1])\n",
      "decoder is torch.Size([1, 13152])\n",
      "targget is torch.Size([1, 1])\n",
      "decoder is torch.Size([1, 13152])\n",
      "targget is torch.Size([1, 1])\n",
      "decoder is torch.Size([1, 13152])\n",
      "targget is torch.Size([1, 1])\n",
      "decoder is torch.Size([1, 13152])\n",
      "targget is torch.Size([1, 1])\n",
      "decoder is torch.Size([1, 13152])\n",
      "targget is torch.Size([1, 1])\n",
      "decoder is torch.Size([1, 13152])\n",
      "targget is torch.Size([1, 1])\n",
      "decoder is torch.Size([1, 13152])\n",
      "targget is torch.Size([1, 1])\n",
      "decoder is torch.Size([1, 13152])\n",
      "targget is torch.Size([1, 1])\n",
      "decoder is torch.Size([1, 13152])\n",
      "targget is torch.Size([1, 1])\n",
      "decoder is torch.Size([1, 13152])\n",
      "targget is torch.Size([1, 1])\n",
      "decoder is torch.Size([1, 13152])\n",
      "targget is torch.Size([1, 1])\n",
      "decoder is torch.Size([1, 13152])\n",
      "targget is torch.Size([1, 1])\n",
      "decoder is torch.Size([1, 13152])\n",
      "targget is torch.Size([1, 1])\n",
      "decoder is torch.Size([1, 13152])\n",
      "targget is torch.Size([1, 1])\n",
      "decoder is torch.Size([1, 13152])\n",
      "targget is torch.Size([1, 1])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-9ee0c130c256>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[0;31m# Run the train function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_variable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_variable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0;31m# Keep track of loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-9ee0c130c256>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(input_variable, target_variable, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mni\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mEOS_token\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3Tfgpu/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \"\"\"\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3Tfgpu/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 98\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#%%\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "\n",
    "import re\n",
    "import time\n",
    "import jieba\n",
    "import random\n",
    "import math\n",
    "import string\n",
    "\n",
    "#%%\n",
    "# # 1.数据处理部分\n",
    "USE_CUDA = False\n",
    "path = 'data/cmn-eng/'\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "MAX_LENGTH = 10\n",
    "\n",
    "def isChinese(sen):\n",
    "    zhPattern = re.compile(u'[\\u4e00-\\u9fa5]+')\n",
    "    return zhPattern.search(sen)\n",
    "# 简化句子 便于处理\n",
    "def normalize_string(s):\n",
    "    s = re.sub(r\"[!！？.()（）\"\"?。“”，,']\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2 # Count SOS and EOS\n",
    "      \n",
    "    def index_words(self, sentence):\n",
    "        sen_list = []\n",
    "        if isChinese(sentence):\n",
    "            sen_list = jieba.cut(sentence)\n",
    "        else:\n",
    "            sen_list = sentence.split(' ')\n",
    "            \n",
    "        for word in sen_list:\n",
    "            self.index_word(word)\n",
    "\n",
    "    def index_word(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "\n",
    "def read_sen(path, lang1, lang2, reverse=False):\n",
    "    with open(path + '{}-{}.txt'.format(lang1, lang2)) as f:\n",
    "        lines = f.readlines()\n",
    "        pairs = []\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if reverse:\n",
    "                line = line.split('\\t')\n",
    "                line.reverse()\n",
    "                line = \"\\t\".join(line)\n",
    "                \n",
    "            pair = [normalize_string(sen) for sen in line.split('\\t')]\n",
    "            pairs.append(pair)\n",
    "        \n",
    "        if reverse:\n",
    "            input_lang = Lang(lang2)\n",
    "            output_lang = Lang(lang1) \n",
    "        else:\n",
    "            input_lang = Lang(lang1)            \n",
    "            output_lang = Lang(lang2)   \n",
    "\n",
    "#         print(\"input_lang is {}\".format(input_lang.n_words))\n",
    "            \n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "def data_preprocess(path, lang1, lang2, reverse=False):\n",
    "    print(\"Read lines......\")\n",
    "    input_lang, output_lang, pairs = read_sen(path, lang1, lang2, reverse)\n",
    "    print(\"Trimmed  to {} sentence pairs\".format(len(pairs)))\n",
    "    \n",
    "    print(\"Indexing words......\")\n",
    "    for pair in pairs:\n",
    "        input_lang.index_words(pair[0])\n",
    "        output_lang.index_words(pair[1])\n",
    "    \n",
    "    return input_lang, output_lang, pairs\n",
    "    \n",
    "input_lang, output_lang, pairs = data_preprocess(path, 'eng', 'cmn')\n",
    "for i in range(5):\n",
    "    print(random.choice(pairs))\n",
    "\n",
    "#%%\n",
    "# # 2.pytorch 搭建模型\n",
    "# ## 2.1.数据部分\n",
    "def indexes_from_sentence(lang, sen):\n",
    "    if isChinese(sen):\n",
    "        sen = jieba.cut('')\n",
    "    else:\n",
    "        sen = sen.split(' ')\n",
    "        \n",
    "    return [lang.word2index[word] for word in sen]\n",
    "\n",
    "def variable_from_sentence(lang, sen):\n",
    "    ixs = indexes_from_sentence(lang, sen)\n",
    "    ixs.append(EOS_token)\n",
    "    var = Variable(torch.LongTensor(ixs).view(-1, 1))\n",
    "    if USE_CUDA: \n",
    "        var = var.cuda()\n",
    "    \n",
    "    return var\n",
    "    \n",
    "\n",
    "def variables_from_pair(pair):\n",
    "    input_variable = variable_from_sentence(input_lang, pair[0])\n",
    "    output_variable = variable_from_sentence(output_lang, pair[1])\n",
    "\n",
    "    return (input_variable, output_variable)\n",
    "\n",
    "\n",
    "#%%\n",
    "# ## 2.2.模型搭建\n",
    "# 编码层\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, batch_first=True)\n",
    "\n",
    "    def forward(self, word_inputs, hidden):\n",
    "        seq_len = len(word_inputs)\n",
    "        embedded = self.embedding(word_inputs).view(1, seq_len, -1)\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        hidden = Variable(torch.zeros(self.n_layers, 1, self.hidden_size))\n",
    "        if USE_CUDA: hidden = hidden.cuda()\n",
    "        return hidden\n",
    "# Attn 层\n",
    "class Attn(nn.Module):\n",
    "    def __init__(self, method, hidden_size):\n",
    "        super(Attn, self).__init__()\n",
    "\n",
    "        self.method = method\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        if self.method == 'general':\n",
    "            self.attn = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "\n",
    "        # else self.method = 'concat':\n",
    "        #     self.attn = \n",
    "        #     self.other = \n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        seq_len = encoder_outputs.size()[1]\n",
    "\n",
    "        attn_energies = Variable(torch.zeros(seq_len))\n",
    "        if USE_CUDA:\n",
    "            attn_energies.cuda()\n",
    "\n",
    "        for i in range(seq_len):\n",
    "            attn_energies[i] = self.score(hidden, encoder_outputs[0][i])\n",
    "\n",
    "        return F.softmax(attn_energies).unsqueeze(0).unsqueeze(0)\n",
    "    \n",
    "    def score(self, hidden, encoder_output):\n",
    "        if self.method == 'general':\n",
    "            energy = self.attn(encoder_output)\n",
    "            # 矩阵维度有些不理解\n",
    "            energy = torch.dot(hidden.view(-1), energy.view(-1))\n",
    "            return energy\n",
    "# 改进的解码层\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, attn_model, hidden_size, output_size, n_layers=1, dropout_p=.1):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        # 定义参数\n",
    "        self.attn_model = attn_model\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        # 定义层\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size * 2, hidden_size, n_layers, dropout=dropout_p, batch_first=True)\n",
    "        # 为什么乘 2\n",
    "        self.out = nn.Linear(hidden_size * 2, output_size)\n",
    "\n",
    "        if attn_model != 'none':\n",
    "            self.attn = Attn(attn_model, hidden_size)\n",
    "\n",
    "    def forward(self, word_input, last_context, last_hidden, encoder_outputs):\n",
    "        word_embedded = self.embedding(word_input).view(1, 1, -1)\n",
    "\n",
    "        rnn_input = torch.cat((word_embedded, last_context.unsqueeze(0)), 2)\n",
    "        rnn_output, hidden = self.gru(rnn_input, last_hidden)\n",
    "\n",
    "        attn_weights = self.attn(rnn_output.squeeze(0), encoder_outputs)\n",
    "        context = attn_weights.bmm(encoder_outputs)\n",
    "        # print(\"context size is {}\".format(context.size()))\n",
    "        rnn_output = rnn_output.squeeze(1)\n",
    "        context =  context.squeeze(0)\n",
    "        # print(\"context size is {}\".format(context.size()))        \n",
    "        # 这块还有点不理解\n",
    "        output = F.log_softmax(self.out(torch.cat((rnn_output, context), 1)))\n",
    "\n",
    "        return output, context, hidden, attn_weights\n",
    "\n",
    "#%%\n",
    "# 对模型进行测试\n",
    "encoder_test = EncoderRNN(10, 10, 2)\n",
    "decoder_test = AttnDecoderRNN('general', 10, 10, 2)\n",
    "\n",
    "# print(encoder_test)\n",
    "# print(decoder_test)\n",
    "\n",
    "encoder_hidden = encoder_test.init_hidden()\n",
    "word_input = Variable(torch.LongTensor([1, 9, 3, 4]))\n",
    "\n",
    "if USE_CUDA:\n",
    "    encoder_test.cuda()\n",
    "    word_input.cuda()\n",
    "\n",
    "encoder_outputs, encoder_hidden = encoder_test(word_input, encoder_hidden)\n",
    "\n",
    "word_inputs = Variable(torch.LongTensor([1, 2, 6, 6, 8]))\n",
    "# 不是很理解\n",
    "decoder_attns = torch.zeros(1, 5, 4)\n",
    "decoder_hidden = encoder_hidden \n",
    "decoder_context = Variable(torch.zeros(1, decoder_test.hidden_size))\n",
    "\n",
    "if USE_CUDA:\n",
    "    decoder_test.cuda()\n",
    "    word_inputs = word_inputs.cuda()\n",
    "    decoder_context = decoder_context.cuda()\n",
    "\n",
    "for i in range(5):\n",
    "    decoder_output, decoder_context, deocder_hidden, decoder_attn = decoder_test(word_inputs[i], decoder_context, decoder_hidden, encoder_outputs)\n",
    "    decoder_attns[0, i] = decoder_attn.squeeze(0).cpu().data\n",
    "    print(decoder_attns)\n",
    "\n",
    "     \n",
    "#%%\n",
    "# 训练\n",
    "teacher_forcing_ratio = .5\n",
    "clip = .5\n",
    "\n",
    "attn_model = 'general'\n",
    "hidden_size = 500\n",
    "n_layers = 2\n",
    "dropout_p = .5\n",
    "\n",
    "encoder = EncoderRNN(input_lang.n_words, hidden_size, n_layers)\n",
    "decoder = AttnDecoderRNN(attn_model, hidden_size, output_lang.n_words, n_layers, dropout_p=dropout_p)\n",
    "\n",
    "if USE_CUDA:\n",
    "    encdoer.cuda()\n",
    "    decoder.cuda()\n",
    "\n",
    "learning_rate = .0001\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "#评判标准\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "n_epochs = 50000\n",
    "plot_every = 200\n",
    "print_every = 1000\n",
    "\n",
    "start = time.time()\n",
    "plot_losses = []\n",
    "print_loss_total = 0\n",
    "plot_loss_total = 0\n",
    "\n",
    "def as_minutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def time_since(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (as_minutes(s), as_minutes(rs))\n",
    "\n",
    "\n",
    "def train(input_variable, target_variable, encoder, decoder, encoder_optimizer, decoder_optimizer,  criterion):\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    loss = 0\n",
    "\n",
    "    input_length = input_variable.size()[0]\n",
    "    target_length = target_variable.size()[0]\n",
    "\n",
    "    encoder_hidden = encoder.init_hidden()\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "  \n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]]))\n",
    "    decoder_context = Variable(torch.zeros(1, decoder.hidden_size))\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    if USE_CUDA:\n",
    "        decoder_input = decoder_input.cuda()\n",
    "        decoder_context = decoder_input.cuda()\n",
    "\n",
    "    use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        \n",
    "        # Teacher forcing: Use the ground-truth target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_context, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_context, decoder_hidden, encoder_outputs)\n",
    "            print(\"decoder is {}\".format(decoder_output.size()))\n",
    "            print(\"targget is {}\".format(target_variable.size()))\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            decoder_input = target_variable[di] # Next target is next input\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use network's own prediction as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_context, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_context, decoder_hidden, encoder_outputs)\n",
    "            print(\"decoder is {}\".format(decoder_output.size()))\n",
    "            print(\"targget is {}\".format(target_variable.size()))\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            \n",
    "            # Get most likely word index (highest value) from output\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            ni = topi[0][0]\n",
    "            \n",
    "            decoder_input = Variable(torch.LongTensor([[ni]])) # Chosen word is next input\n",
    "            if USE_CUDA: decoder_input = decoder_input.cuda()\n",
    "\n",
    "            # Stop at end of sentence (not necessary when using known targets)\n",
    "            if ni == EOS_token: break\n",
    "        \n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm(encoder.parameters(), clip)\n",
    "    torch.nn.utils.clip_grad_norm(decoder.parameters(), clip)   \n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.data[0]/target_length\n",
    "\n",
    "\n",
    "# Begin!\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    \n",
    "    # Get training data for this cycle\n",
    "    training_pair = variables_from_pair(random.choice(pairs))\n",
    "    input_variable = training_pair[0]\n",
    "    target_variable = training_pair[1]\n",
    "\n",
    "    # Run the train function\n",
    "    loss = train(input_variable, target_variable, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "\n",
    "    # Keep track of loss\n",
    "    print_loss_total += loss\n",
    "    plot_loss_total += loss\n",
    "\n",
    "    if epoch == 0: continue\n",
    "\n",
    "    if epoch % print_every == 0:\n",
    "        print_loss_avg = print_loss_total / print_every\n",
    "        print_loss_total = 0\n",
    "        print_summary = '%s (%d %d%%) %.4f' % (time_since(start, epoch / n_epochs), epoch, epoch / n_epochs * 100, print_loss_avg)\n",
    "        print(print_summary)\n",
    "\n",
    "    if epoch % plot_every == 0:\n",
    "        plot_loss_avg = plot_loss_total / plot_every\n",
    "        plot_losses.append(plot_loss_avg)\n",
    "        plot_loss_total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
