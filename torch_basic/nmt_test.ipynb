{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk import FreqDist\n",
    "\n",
    "import re\n",
    "import jieba\n",
    "import math\n",
    "import time\n",
    "from collections import Counter\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '../data/cmn-eng/'\n",
    "\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "MAX_LENGTH = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 工具函数\n",
    "def deal_en_sen(raw):\n",
    "    raw.strip()\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", raw)\n",
    "    words = letters_only.lower().split()\n",
    "\n",
    "    return (\" \".join(words))\n",
    "\n",
    "def deal_zh_sen(raw):\n",
    "    raw.strip()\n",
    "    letters_only = re.sub(\"[^\\u4e00-\\u9fa5]\", \"\", raw)                        \n",
    "    \n",
    "    return(letters_only) \n",
    "\n",
    "def word2index(vocab):\n",
    "    return {word: i for i, word in enumerate(vocab)}\n",
    "\n",
    "def sen2index(sen, lang):\n",
    "    global word2index_en\n",
    "    global word2index_zh\n",
    "    if lang == 'en':\n",
    "        return [word2index_en[word] for word in sen.split(' ')]\n",
    "    else:\n",
    "        return [word2index_zh[word] for word in list(jieba.cut(sen))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 数据预处理\n",
    "with open(path + 'cmn.txt') as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "en_sens = [deal_en_sen(line.split('\\t')[0]) for line in lines]\n",
    "zh_sens = [deal_zh_sen(line.split('\\t')[1]) for line in lines]\n",
    "pairs = [[en, zh] for en, zh in zip (en_sens, zh_sens)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['hi', '嗨'], ['hi', '你好'], ['run', '你用跑的'], ['wait', '等等'], ['hello', '你好']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "en_max_len = max([len(x) for x in en_sens])\n",
    "print(en_max_len)\n",
    "zh_max_len = max([len(x) for x in zh_sens])\n",
    "print(zh_max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.786 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "# 借助 NLTK 函数\n",
    "en_word_counts = FreqDist(' '.join(en_sens).split(' '))\n",
    "# zh_word_counts = FreqDist(list(jieba.cut(''.join(zh_sens))))\n",
    "en_vocab = set(en_word_counts)\n",
    "# zh_vocab = set(zh_word_counts)\n",
    "zh_counts = Counter()\n",
    "for sen in zh_sens:\n",
    "    for word in list(jieba.cut(sen)):\n",
    "        zh_counts[word] += 1\n",
    "        \n",
    "zh_vocab = set(zh_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19056\n",
      "9093\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['hi', '嗨'],\n",
       " ['hi', '你好'],\n",
       " ['run', '你用跑的'],\n",
       " ['wait', '等等'],\n",
       " ['hello', '你好'],\n",
       " ['i try', '让我来']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 作用是什么???\n",
    "# word2index_en = {0: \"SOS\", 1: \"EOS\"}\n",
    "# word2index_zh = {0: \"SOS\", 1: \"EOS\"}\n",
    "# 为了便于训练长度过长的句子都被过滤掉了\n",
    "MAX_LENGTH = 7\n",
    "print(len(pairs))\n",
    "filter_pairs = [pair for pair in pairs if len(pair[0].split(' ')) < MAX_LENGTH and len(list(jieba.cut(pair[1]))) < MAX_LENGTH]\n",
    "print(len(filter_pairs))\n",
    "filter_pairs[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# word2index\n",
    "# { 't' + str(x) : x  for x in range(10)}\n",
    "word2index_en = word2index(en_vocab)\n",
    "word2index_zh = word2index(zh_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[3064], [3716]],\n",
       " [[3064], [6496]],\n",
       " [[3625], [9462, 12034, 7352, 4108]],\n",
       " [[1022], [11788]],\n",
       " [[2693], [6496]],\n",
       " [[2636, 2138], [8845, 7245, 144]]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen_vector = [[sen2index(pair[0], 'en'), sen2index(pair[1], 'zh')] for pair in filter_pairs]\n",
    "sen_vector[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 模型实现\n",
    "# seq2seq with attention\n",
    "# np.array([sen_vector[2][1]]).shape\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1, iscuda=False):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.iscuda = iscuda\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers)\n",
    "\n",
    "    def forward(self, word_inputs, hidden):\n",
    "        seq_len = len(word_inputs)\n",
    "        embedded = self.embedding(word_inputs).view(seq_len, 1, -1)\n",
    "        output, hidden = self.gru()\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        hidden = Variable(torch.zeros(self.n_layers, 1, self.hidden_size))\n",
    "        if self.iscuda: hidden = hidden.cuda()\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Attn(nn.Module):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-14-80d194a492ad>, line 23)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-14-80d194a492ad>\"\u001b[0;36m, line \u001b[0;32m23\u001b[0m\n\u001b[0;31m    attn_weights =\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, attn_model, hidden_size, output_size, n_layers=1):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        \n",
    "        self.attn_model = attn_model\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        # self.gru = nn.GRU()\n",
    "        # self.out = nn.Linear()\n",
    "        \n",
    "        if attn_model != 'none':\n",
    "            self.attn = Attn(attn_model, hidden_size)\n",
    "        \n",
    "    def forward(self, word_input, last_context, last_hiddden, encoder_outputs):\n",
    "        word_embedded = self.embedding(word_input).view(1, 1, -1)\n",
    "        \n",
    "        rnn_input = torch.cat((), 2)\n",
    "        rnn_output, hidden = self.gr\n",
    "        \n",
    "        attn_weights = \n",
    "        context = \n",
    "        \n",
    "        rnn_output = \n",
    "        context = \n",
    "        output = \n",
    "        \n",
    "        return output, context, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = random.choice(sen_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.LongTensor([a[0]]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Attn(nn.Module):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# teacher forcing and clip\n",
    "teacher_forcing_ratio = 0.5\n",
    "clip = 5.0\n",
    "\n",
    "def train():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 训练\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.Size([1, 3])'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(Variable(torch.LongTensor([[1, 2, 3]])).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding = nn.Embedding(10, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "(0 ,.,.) = \n",
       "  0.7268 -1.4654  0.4456\n",
       "  0.3283 -0.0743 -1.6886\n",
       " -0.9762 -0.7372  0.4493\n",
       "[torch.FloatTensor of size 1x3x3]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = Variable(torch.LongTensor([[1,2,3]]))\n",
    "embedding(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.7268 -1.4654  0.4456\n",
       " 0.3283 -0.0743 -1.6886\n",
       "-0.9762 -0.7372  0.4493\n",
       "[torch.FloatTensor of size 3x3]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = Variable(torch.LongTensor([1,2,3]))\n",
    "embedding(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "(0 ,.,.) = \n",
       "\n",
       "Columns 0 to 8 \n",
       "   0.2564  0.3946  0.0448  0.7466  0.3270  0.9833  0.2773  0.5504  0.8895\n",
       "\n",
       "Columns 9 to 9 \n",
       "   0.5512\n",
       "\n",
       "(1 ,.,.) = \n",
       "\n",
       "Columns 0 to 8 \n",
       "   0.3280  0.2546  0.4371  0.9851  0.3637  0.2349  0.2125  0.2808  0.3715\n",
       "\n",
       "Columns 9 to 9 \n",
       "   0.6756\n",
       "\n",
       "(2 ,.,.) = \n",
       "\n",
       "Columns 0 to 8 \n",
       "   0.7372  0.8875  0.3707  0.2788  0.3977  0.8162  0.4258  0.0757  0.4776\n",
       "\n",
       "Columns 9 to 9 \n",
       "   0.9132\n",
       "[torch.FloatTensor of size 3x1x10]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Variable(torch.rand(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = Variable(torch.Tensor([[[1, 2, 3, 4, 5, 6, 9999]]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "    1\n",
       "    2\n",
       "    3\n",
       "    4\n",
       "    5\n",
       "    6\n",
       " 9999\n",
       "[torch.FloatTensor of size 7]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 7])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cannot call .data on a torch.Tensor: did you intend to use autograd.Variable?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-10a7d2617730>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/quoniammm/anaconda3/envs/py3Tfgpu/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mdata\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cannot call .data on a torch.Tensor: did you intend to use autograd.Variable?'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cannot call .data on a torch.Tensor: did you intend to use autograd.Variable?"
     ]
    }
   ],
   "source": [
    "a.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a =torch.LongTensor([[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1\n",
       "[torch.LongTensor of size 1x1]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'torch.LongTensor' object does not support indexing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-4a0afa265c74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'torch.LongTensor' object does not support indexing"
     ]
    }
   ],
   "source": [
    "torch.LongTensor(a - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = Variable(torch.Tensor([[[0, 0, 0, 0, 0, 0]]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       " (0 ,.,.) = \n",
       "   0\n",
       " [torch.FloatTensor of size 1x1x1], Variable containing:\n",
       " (0 ,.,.) = \n",
       "   5\n",
       " [torch.LongTensor of size 1x1x1])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.topk(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk import FreqDist\n",
    "\n",
    "import re\n",
    "import jieba\n",
    "import math\n",
    "import time\n",
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "path = '../data/cmn-eng/'\n",
    "\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "MAX_LENGTH = 10\n",
    "\n",
    "# 工具函数\n",
    "def deal_en_sen(raw):\n",
    "    raw.strip()\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", raw)\n",
    "    words = letters_only.lower().split()\n",
    "\n",
    "    return (\" \".join(words))\n",
    "\n",
    "def deal_zh_sen(raw):\n",
    "    raw.strip()\n",
    "    letters_only = re.sub(\"[^\\u4e00-\\u9fa5]\", \"\", raw)                        \n",
    "    \n",
    "    return(letters_only) \n",
    "\n",
    "def word2index(vocab):\n",
    "    return {word: i + 1 for i, word in enumerate(vocab)}\n",
    "\n",
    "def sen2index(sen, lang):\n",
    "    global word2index_en\n",
    "    global word2index_zh\n",
    "    if lang == 'en':\n",
    "        no_eos = [word2index_en[word] for word in sen.split(' ')]\n",
    "    else:\n",
    "        no_eos = [word2index_zh[word] for word in list(jieba.cut(sen))]\n",
    "    no_eos.append(0)\n",
    "    return no_eos\n",
    "    \n",
    "def as_minutes(s):\n",
    "    pass\n",
    "\n",
    "def time_since(since, percent):\n",
    "    pass\n",
    "    \n",
    "# 数据预处理\n",
    "with open(path + 'cmn.txt') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "en_sens = [deal_en_sen(line.split('\\t')[0]) for line in lines]\n",
    "zh_sens = [deal_zh_sen(line.split('\\t')[1]) for line in lines]\n",
    "pairs = [[en, zh] for en, zh in zip (en_sens, zh_sens)] \n",
    "\n",
    "en_max_len = max([len(x) for x in en_sens])\n",
    "zh_max_len = max([len(x) for x in zh_sens])\n",
    "\n",
    "# 借助 NLTK 函数\n",
    "en_word_counts = FreqDist(' '.join(en_sens).split(' '))\n",
    "# zh_word_counts = FreqDist(list(jieba.cut(''.join(zh_sens))))\n",
    "en_vocab = set(en_word_counts)\n",
    "# zh_vocab = set(zh_word_counts)\n",
    "zh_counts = Counter()\n",
    "for sen in zh_sens:\n",
    "    for word in list(jieba.cut(sen)):\n",
    "        zh_counts[word] += 1\n",
    "        \n",
    "zh_vocab = set(zh_counts)\n",
    "\n",
    "MAX_LENGTH = 7\n",
    "filter_pairs = [pair for pair in pairs if len(pair[0].split(' ')) < MAX_LENGTH and len(list(jieba.cut(pair[1]))) < MAX_LENGTH]\n",
    "\n",
    "word2index_en = word2index(en_vocab)\n",
    "word2index_en[0] = 'EOS'\n",
    "word2index_zh = word2index(zh_vocab)\n",
    "word2index_zh[0] = 'EOS'\n",
    "sen_vector = [[sen2index(pair[0], 'en'), sen2index(pair[1], 'zh')] for pair in filter_pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[5420, 0], [2934, 0]],\n",
       " [[5420, 0], [630, 0]],\n",
       " [[792, 0], [2905, 3815, 9543, 11548, 0]],\n",
       " [[970, 0], [9899, 0]],\n",
       " [[5632, 0], [630, 0]],\n",
       " [[3566, 354, 0], [12825, 5960, 3425, 0]]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen_vector[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "a= [1, 3]\n",
    "print(a.append(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.LongTensor([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0\n",
       "[torch.LongTensor of size 1]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
